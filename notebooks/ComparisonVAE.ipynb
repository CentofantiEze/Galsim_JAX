{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a0322c92-da80-494e-a53c-341ee3c11b8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-11 14:29:29.048975: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-09-11 14:29:29.096443: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-09-11 14:29:29.923732: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: gpu\n",
      "Number of avaliable devices : 1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "import jax\n",
    "from jax.lib import xla_bridge\n",
    "\n",
    "# Set the CUDA_VISIBLE_DEVICES environment variable\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = str('0')\n",
    "os.environ[\"XLA_FLAGS\"] = \"--xla_gpu_cuda_data_dir=/usr/local/cuda-12.1\"\n",
    "os.environ[\"XLA_FLAGS\"] = \"--xla_gpu_force_compilation_parallelism=1\"\n",
    "\n",
    "# Checking for GPU access\n",
    "print(\"Device: {}\".format(xla_bridge.get_backend().platform))\n",
    "\n",
    "# Checking the GPU available\n",
    "gpus = jax.devices(\"gpu\")\n",
    "print(\"Number of avaliable devices : {}\".format(len(gpus)))\n",
    "\n",
    "# Ensure TF does not see GPU and grab all GPU memory.\n",
    "tf.config.set_visible_devices([], device_type=\"GPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e56bdb3f-fab4-4896-9cf3-0138e67e01e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "import numpy as np\n",
    "import jax.numpy as jnp\n",
    "import optax\n",
    "import wandb\n",
    "import logging\n",
    "\n",
    "from astropy.stats import mad_std\n",
    "from tensorflow_probability.substrates import jax as tfp\n",
    "from flax import linen as nn  # Linen API\n",
    "from jax import random\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# Loading the dataset and transforming it to NumPy Arrays\n",
    "train_dset, info = tfds.load(name='hsc_photoz', with_info=True, split=\"train\")\n",
    "\n",
    "# What's in our dataset:\n",
    "# info\n",
    "\n",
    "# Let's collect a few examples to check their distributions\n",
    "cutouts = []\n",
    "specz = []\n",
    "for entry in train_dset.take(1000):\n",
    "    specz.append(entry[\"attrs\"][\"specz_redshift\"])\n",
    "    cutouts.append(entry[\"image\"])\n",
    "\n",
    "cutouts = np.stack(cutouts)\n",
    "specz = np.stack(specz)\n",
    "\n",
    "scaling = []\n",
    "\n",
    "for i, _ in enumerate([\"g\", \"r\", \"i\", \"z\", \"y\"]):\n",
    "    sigma = mad_std(\n",
    "        cutouts[..., i].flatten()\n",
    "    )  # Capturing the std devation of each band\n",
    "    scaling.append(sigma)\n",
    "\n",
    "# Using a mapping function to apply preprocessing to our data\n",
    "def preprocessing(example):\n",
    "    img = tf.math.asinh(example[\"image\"] / tf.constant(scaling) / 3.0)\n",
    "    # We return the image as our input and output for a generative model\n",
    "    return img\n",
    "\n",
    "def input_fn(mode=\"train\", batch_size=64):\n",
    "    \"\"\"\n",
    "    mode: 'train' or 'test'\n",
    "    \"\"\"\n",
    "    if mode == \"train\":\n",
    "        dataset = tfds.load('hsc_photoz', split=\"train[:80%]\")\n",
    "        dataset = dataset.repeat()\n",
    "        dataset = dataset.shuffle(10000)\n",
    "    else:\n",
    "        dataset = tfds.load('hsc_photoz', split=\"train[80%:]\")\n",
    "\n",
    "    dataset = dataset.batch(batch_size, drop_remainder=True)\n",
    "    dataset = dataset.map(preprocessing)  # Apply data preprocessing\n",
    "    dataset = dataset.prefetch(\n",
    "        -1\n",
    "    )  # fetch next batches while training current one (-1 for autotune)\n",
    "    return dataset\n",
    "\n",
    "# Dataset as a numpy iterator\n",
    "dset = input_fn().as_numpy_iterator()\n",
    "\n",
    "# Generating a random key for JAX\n",
    "rng = random.PRNGKey(0)\n",
    "# Size of the input to initialize the encoder parameters\n",
    "batch_enc = jnp.ones((1, 64, 64, 5))\n",
    "\n",
    "latent_dim = 64\n",
    "c_hidden_enc = (64, 128, 256)\n",
    "num_blocks_enc = (1, 1, 1)\n",
    "c_hidden_dec = (128, 64, 32, 5)\n",
    "num_blocks_dec = (1, 1, 1, 1)\n",
    "\n",
    "# Size of the input to initialize the decoder parameters\n",
    "batch_dec = jnp.ones((1, 4, 4, 64))\n",
    "\n",
    "act_fn = nn.leaky_relu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0ba241a3-b9e8-41b9-8e34-ffef5e43581d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from flax import linen as nn  # Linen API\n",
    "from tensorflow_probability.substrates import jax as tfp\n",
    "\n",
    "# Loading distributions and bijectors from TensorFlow Probability (JAX version)\n",
    "tfd = tfp.distributions\n",
    "tfb = tfp.bijectors\n",
    "\n",
    "\n",
    "class ResNetBlock(nn.Module):\n",
    "    \"\"\"Creates a block of a CNN with ResNet architecture to encode or decode images.\"\"\"\n",
    "\n",
    "    act_fn: callable  # Activation function\n",
    "    c_out: int  # Output feature size\n",
    "    subsample: bool = False  # If True, we apply a stride inside F\n",
    "\n",
    "    @nn.compact\n",
    "    def __call__(self, x, encode=True):\n",
    "        # Network representing F\n",
    "        print(\"Input X Resnet\", x.shape)\n",
    "        if encode:\n",
    "            z = nn.Conv(self.c_out, kernel_size=(3, 3), padding=\"SAME\", strides=(2, 2))(\n",
    "                x\n",
    "            )\n",
    "            print(\"Z Resnet\", z.shape)\n",
    "            z = self.act_fn(z)\n",
    "            x = nn.Conv(self.c_out, kernel_size=(3, 3), padding=\"SAME\", strides=(2, 2))(\n",
    "                x\n",
    "            )\n",
    "            print(\"Sum X Resnet\", x.shape)\n",
    "\n",
    "        else:\n",
    "            z = nn.ConvTranspose(\n",
    "                self.c_out, kernel_size=(3, 3), padding=\"SAME\", strides=(2, 2)\n",
    "            )(x)\n",
    "            print(\"Z Resnet\", z.shape)\n",
    "            z = self.act_fn(z)\n",
    "            x = nn.ConvTranspose(\n",
    "                self.c_out, kernel_size=(3, 3), padding=\"SAME\", strides=(2, 2)\n",
    "            )(x)\n",
    "            print(\"Sum X Resnet\", x.shape)\n",
    "\n",
    "        x_out = self.act_fn(z + x)\n",
    "        return x_out\n",
    "\n",
    "\n",
    "class ResNetEnc(nn.Module):\n",
    "    \"\"\" \"Creates a small convolutional encoder using ResNet blocks as intermediate layers\"\"\"\n",
    "\n",
    "    act_fn: callable\n",
    "    block_class: nn.Module\n",
    "    num_blocks: tuple = (1, 1, 1)\n",
    "    c_hidden: tuple = (64, 128, 256)\n",
    "    latent_dim: int = 64\n",
    "\n",
    "    @nn.compact\n",
    "    def __call__(self, x, encode=True):\n",
    "        # A first convolution on the original image to scale up the channel size\n",
    "        print(x.shape)\n",
    "        x = nn.Conv(\n",
    "            self.latent_dim, kernel_size=(3, 3), padding=\"SAME\", strides=(2, 2)\n",
    "        )(x)\n",
    "        x = self.act_fn(x)\n",
    "        print(x.shape)\n",
    "\n",
    "        # Creating the ResNet blocks\n",
    "        for block_idx, block_count in enumerate(self.num_blocks):\n",
    "            for bc in range(block_count):\n",
    "                # Subsample the first block of each group, except the very first one.\n",
    "                subsample = bc == 0 and block_idx > 0\n",
    "                # ResNet block\n",
    "                x = self.block_class(\n",
    "                    c_out=self.c_hidden[block_idx],\n",
    "                    act_fn=self.act_fn,\n",
    "                    subsample=subsample,\n",
    "                )(x, encode=True)\n",
    "\n",
    "        net = nn.Dense(features=self.latent_dim * 2)(x)\n",
    "        # Image is now 4x4x128\n",
    "        print(\"Dense shape\", net.shape, \"\\n\")\n",
    "\n",
    "        q = tfd.MultivariateNormalDiag(\n",
    "            loc=net[..., : self.latent_dim], scale_diag=net[..., self.latent_dim :]\n",
    "        )\n",
    "\n",
    "        return q\n",
    "\n",
    "\n",
    "class ResNetDec(nn.Module):\n",
    "    \"\"\" \"Creates a small convolutional decoder using ResNet blocks as intermediate layers\"\"\"\n",
    "\n",
    "    act_fn: callable\n",
    "    block_class: nn.Module\n",
    "    num_blocks: tuple = (1, 1, 1, 1)\n",
    "    c_hidden: tuple = (128, 64, 32, 5)\n",
    "\n",
    "    @nn.compact\n",
    "    def __call__(self, x, encode=False):\n",
    "        # Creating the ResNet blocks\n",
    "        for block_idx, block_count in enumerate(self.num_blocks):\n",
    "            for bc in range(block_count):\n",
    "                # Subsample the first block of each group, except the very first one.\n",
    "                subsample = bc == 0 and block_idx > 0\n",
    "                # ResNet block\n",
    "                x = self.block_class(\n",
    "                    c_out=self.c_hidden[block_idx],\n",
    "                    act_fn=self.act_fn,\n",
    "                    subsample=subsample,\n",
    "                )(x, encode=False)\n",
    "\n",
    "        x = nn.activation.softplus(x)\n",
    "        # Image is now 64x64x5\n",
    "        r = tfd.MultivariateNormalDiag(loc=x, scale_diag=[0.01, 0.01, 0.01, 0.01, 0.01])\n",
    "\n",
    "        return r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0cf94e2b-7adc-40e9-89ac-c014684dfcd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 64, 64, 5)\n",
      "(1, 32, 32, 64)\n",
      "Input X Resnet (1, 32, 32, 64)\n",
      "Z Resnet (1, 16, 16, 64)\n",
      "Sum X Resnet (1, 16, 16, 64)\n",
      "Input X Resnet (1, 16, 16, 64)\n",
      "Z Resnet (1, 8, 8, 128)\n",
      "Sum X Resnet (1, 8, 8, 128)\n",
      "Input X Resnet (1, 8, 8, 128)\n",
      "Z Resnet (1, 4, 4, 256)\n",
      "Sum X Resnet (1, 4, 4, 256)\n",
      "Dense shape (1, 4, 4, 128) \n",
      "\n",
      "Input X Resnet (1, 4, 4, 64)\n",
      "Z Resnet (1, 8, 8, 128)\n",
      "Sum X Resnet (1, 8, 8, 128)\n",
      "Input X Resnet (1, 8, 8, 128)\n",
      "Z Resnet (1, 16, 16, 64)\n",
      "Sum X Resnet (1, 16, 16, 64)\n",
      "Input X Resnet (1, 16, 16, 64)\n",
      "Z Resnet (1, 32, 32, 32)\n",
      "Sum X Resnet (1, 32, 32, 32)\n",
      "Input X Resnet (1, 32, 32, 32)\n",
      "Z Resnet (1, 64, 64, 5)\n",
      "Sum X Resnet (1, 64, 64, 5)\n"
     ]
    }
   ],
   "source": [
    "# Initializing the Encoder\n",
    "Encoder = ResNetEnc(\n",
    "    act_fn=act_fn,\n",
    "    block_class=ResNetBlock,\n",
    "    latent_dim=latent_dim,\n",
    "    c_hidden=c_hidden_enc,\n",
    "    num_blocks=num_blocks_enc,\n",
    ")\n",
    "params_enc = Encoder.init(rng, batch_enc)\n",
    "\n",
    "# Taking 64 images of the dataset\n",
    "batch_im = next(dset)\n",
    "# Generating new keys to use them for inference\n",
    "rng, rng_1 = random.split(rng)\n",
    "\n",
    "# Initializing the Decoder\n",
    "Decoder = ResNetDec(\n",
    "    act_fn=act_fn,\n",
    "    block_class=ResNetBlock,\n",
    "    c_hidden=c_hidden_dec,\n",
    "    num_blocks=num_blocks_dec,\n",
    ")\n",
    "params_dec = Decoder.init(rng_1, batch_dec)\n",
    "\n",
    "# Defining a general list of the parameters\n",
    "params = [params_enc, params_dec]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0779244c-2768-4ec9-a2de-d59153e1a3d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:   1 of 1 files downloaded.  \n"
     ]
    }
   ],
   "source": [
    "import wandb\n",
    "api = wandb.Api()\n",
    "\n",
    "run = api.run(\"jonnyytorres/resnet-comp-dim/0swrd6wi\")\n",
    "artifact = api.artifact('jonnyytorres/resnet-comp-dim/0swrd6wi-checkpoint:best', type='model')\n",
    "artifact_dir = artifact.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0cf1acd0-a901-4829-8655-b1d8ce128ed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from flax.serialization import to_state_dict, msgpack_serialize, from_bytes\n",
    "\n",
    "def load_checkpoint(ckpt_file, state):\n",
    "    \"\"\"Loads the best Wandb checkpoint.\"\"\"\n",
    "    # artifact = wandb.use_artifact(f\"artifacts/{run.id}-checkpoint:v72/\")\n",
    "    artifact_dir = f\"artifacts/{run.id}-checkpoint:best/\"\n",
    "    ckpt_path = os.path.join(artifact_dir, ckpt_file)\n",
    "    with open(ckpt_path, \"rb\") as data_file:\n",
    "        byte_data = data_file.read()\n",
    "    return from_bytes(state, byte_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9d389fc6-fe8d-4905-a58e-5112bac9d68b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16, 64, 64, 5)\n",
      "(16, 32, 32, 64)\n",
      "Input X Resnet (16, 32, 32, 64)\n",
      "Z Resnet (16, 16, 16, 64)\n",
      "Sum X Resnet (16, 16, 16, 64)\n",
      "Input X Resnet (16, 16, 16, 64)\n",
      "Z Resnet (16, 8, 8, 128)\n",
      "Sum X Resnet (16, 8, 8, 128)\n",
      "Input X Resnet (16, 8, 8, 128)\n",
      "Z Resnet (16, 4, 4, 256)\n",
      "Sum X Resnet (16, 4, 4, 256)\n",
      "Dense shape (16, 4, 4, 128) \n",
      "\n",
      "Input X Resnet (16, 4, 4, 64)\n",
      "Z Resnet (16, 8, 8, 128)\n",
      "Sum X Resnet (16, 8, 8, 128)\n",
      "Input X Resnet (16, 8, 8, 128)\n",
      "Z Resnet (16, 16, 16, 64)\n",
      "Sum X Resnet (16, 16, 16, 64)\n",
      "Input X Resnet (16, 16, 16, 64)\n",
      "Z Resnet (16, 32, 32, 32)\n",
      "Sum X Resnet (16, 32, 32, 32)\n",
      "Input X Resnet (16, 32, 32, 32)\n",
      "Z Resnet (16, 64, 64, 5)\n",
      "Sum X Resnet (16, 64, 64, 5)\n"
     ]
    }
   ],
   "source": [
    " # Loading checkpoint for the best step\n",
    "params = load_checkpoint(\"checkpoint.msgpack\", params)\n",
    "\n",
    "# Predicting over an example of data\n",
    "dataset_eval = input_fn(\"test\")\n",
    "test_iterator = dataset_eval.as_numpy_iterator()\n",
    "batch = next(test_iterator)\n",
    "# Taking 16 images as example\n",
    "batch = batch[:16, ...]\n",
    "\n",
    "# Dividing the list of parameters obtained before\n",
    "params_enc, params_dec = params\n",
    "# Distribution of latent space calculated using the batch of data\n",
    "q = ResNetEnc(\n",
    "    act_fn=act_fn,\n",
    "    block_class=ResNetBlock,\n",
    "    latent_dim=latent_dim,\n",
    "    c_hidden=c_hidden_enc,\n",
    "    num_blocks=num_blocks_enc,\n",
    ").apply(params_enc, batch)\n",
    "# Sampling from the distribution\n",
    "z = q.sample(seed=rng_1)\n",
    "\n",
    "# Posterior distribution\n",
    "p = ResNetDec(\n",
    "    act_fn=act_fn,\n",
    "    block_class=ResNetBlock,\n",
    "    c_hidden=c_hidden_dec,\n",
    "    num_blocks=num_blocks_dec,\n",
    ").apply(params_dec, z)\n",
    "# Sample some variables from the posterior distribution\n",
    "rng, rng_1 = random.split(rng)\n",
    "z = p.sample(seed=rng_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b443cda9-d8f2-4a51-9121-4fcd01e1fc3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO PLOT ORIGINAL HSC IMAGES IN BLUE\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig = plt.figure(figsize=(10,10))\n",
    "for i in range(16):\n",
    "    z_img = batch[i, ...]\n",
    "    plt.subplot(4,4,i+1)\n",
    "    plt.imshow((z_img.mean(axis=-1)))\n",
    "    plt.axis('off')\n",
    "\n",
    "# Adjust the layout of the subplots\n",
    "fig.tight_layout()\n",
    "\n",
    "plt.savefig('hsc_examples.png')\n",
    "plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "260a6a93-2274-48dd-8c9e-13765cfda7e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO PLOT ORIGINAL HSC IMAGES IN FALSE COLOR\n",
    "\n",
    "from astropy.visualization import make_lupton_rgb\n",
    "\n",
    "def luptonize(img):\n",
    "  return make_lupton_rgb(img[:,:,2], img[:,:,1], img[:,:,0],\n",
    "                         Q=15, stretch=0.5, minimum=0)\n",
    "\n",
    "fig = plt.figure(figsize=(10,10))\n",
    "for i, entry in enumerate(train_dset.take(16)):\n",
    "    plt.subplot(4,4,i+1)\n",
    "    plt.imshow(luptonize(entry['image']))\n",
    "    # plt.imshow(luptonize(z_img))\n",
    "    plt.axis('off')\n",
    "\n",
    "# Adjust the layout of the subplots\n",
    "fig.tight_layout()\n",
    "\n",
    "plt.savefig('hsc_examples_color.png')\n",
    "plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c30ec506-f395-4604-b963-da024c2b72e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def save_samples(z, name):\n",
    "    # Plotting 16 images of the estimated shape of galaxies\n",
    "    num_rows, num_cols = 3, 8\n",
    "\n",
    "    fig, axes = plt.subplots(num_rows, num_cols, figsize=(25, 9))\n",
    "\n",
    "    for i, (ax1, ax2, ax3) in enumerate(zip(axes[0, :], axes[1, :], axes[2, :])):\n",
    "        batch_img = batch[i, ...]\n",
    "        z_img = z[i, ...]\n",
    "\n",
    "        # Plotting original image\n",
    "        ax1.imshow(batch_img.mean(axis=-1))\n",
    "        ax1.axis(\"off\")\n",
    "        # Plotting predicted image\n",
    "        ax2.imshow(z_img.mean(axis=-1))\n",
    "        ax2.axis(\"off\")\n",
    "        # Plotting difference between original and predicted image\n",
    "        ax3.imshow(z_img.mean(axis=-1) - batch_img.mean(axis=-1))\n",
    "        ax3.axis(\"off\")\n",
    "\n",
    "    # Add a title to the figure\n",
    "    fig.suptitle(\"Samples of predicted galaxies\", fontsize=16)\n",
    "\n",
    "    # Adjust the layout of the subplots\n",
    "    fig.tight_layout()\n",
    "\n",
    "    plt.savefig(name)\n",
    "    plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7db5c74c-367a-4f1a-9aae-8cb85bac24f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the samples of the predicted images and their difference from the original images\n",
    "save_samples(z, 'HSC_First_Model.png')\n",
    "\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0d8bc2fc-5975-434e-a977-6181adca11fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset as a numpy iterator\n",
    "dset = input_fn().as_numpy_iterator()\n",
    "\n",
    "# Generating a random key for JAX\n",
    "rng, rng_2 = jax.random.PRNGKey(0), jax.random.PRNGKey(1)\n",
    "# Size of the input to initialize the encoder parameters\n",
    "batch_autoenc = jnp.ones((1, 64, 64, 5))\n",
    "\n",
    "latent_dim = 64\n",
    "act_fn = nn.gelu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "88cc9aba-26ab-42ae-86e8-cd6ed326b319",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import numpy as np\n",
    "from flax import linen as nn\n",
    "from tensorflow_probability.substrates import jax as tfp\n",
    "\n",
    "# Loading distributions from TensorFlow Probability (JAX version)\n",
    "tfd = tfp.distributions\n",
    "\n",
    "\n",
    "def Normalize(num_groups=10):\n",
    "    return nn.GroupNorm(num_groups=num_groups, epsilon=1e-6, use_scale=True)\n",
    "\n",
    "\n",
    "class Downsample(nn.Module):\n",
    "    in_channels: int\n",
    "\n",
    "    def setup(self):\n",
    "        self.conv = nn.Conv(\n",
    "            self.in_channels,\n",
    "            kernel_size=(3, 3),\n",
    "            strides=(2, 2),\n",
    "            padding=((0, 1), (0, 1)),\n",
    "        )\n",
    "\n",
    "    def __call__(self, x):\n",
    "        pad = ((0, 0), (0, 1), (0, 0), (0, 1))\n",
    "        x = jnp.pad(x, pad, mode=\"constant\", constant_values=0)\n",
    "        x = self.conv(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class ResnetBlock(nn.Module):\n",
    "    in_channels: int\n",
    "    out_channels: int\n",
    "    act_fn: callable = nn.gelu  # Activation function\n",
    "\n",
    "    def setup(self):\n",
    "        self.norm1 = Normalize(num_groups=5)\n",
    "        self.conv1 = nn.Conv(\n",
    "            self.out_channels,\n",
    "            kernel_size=(3, 3),\n",
    "            strides=(1, 1),\n",
    "            padding=((1, 1), (1, 1)),\n",
    "        )\n",
    "        self.norm2 = Normalize(num_groups=5)\n",
    "        self.conv2 = nn.Conv(\n",
    "            self.out_channels,\n",
    "            kernel_size=(3, 3),\n",
    "            strides=(1, 1),\n",
    "            padding=((1, 1), (1, 1)),\n",
    "        )\n",
    "\n",
    "        self.nin_shortcut = nn.Conv(\n",
    "            self.out_channels,\n",
    "            kernel_size=(1, 1),\n",
    "            strides=(1, 1),\n",
    "            padding=((0, 0), (0, 0)),\n",
    "        )\n",
    "\n",
    "    def __call__(self, x):\n",
    "        h = x\n",
    "        h = self.norm1(h)\n",
    "        h = self.act_fn(h)\n",
    "        h = self.conv1(h)\n",
    "        h = self.norm2(h)\n",
    "        h = self.act_fn(h)\n",
    "        h = self.conv2(h)\n",
    "        x = self.nin_shortcut(x)\n",
    "        x_ = x + h\n",
    "\n",
    "        return x + h\n",
    "\n",
    "\n",
    "class DownsamplingBlock(nn.Module):\n",
    "    ch: int\n",
    "    ch_mult: tuple\n",
    "    num_res_blocks: int\n",
    "    resolution: int\n",
    "    block_idx: int\n",
    "    act_fn: callable = nn.gelu  # Activation function\n",
    "\n",
    "    def setup(self):\n",
    "        self.ch_mult_ = self.ch_mult\n",
    "        self.num_resolutions = len(self.ch_mult_)\n",
    "        in_ch_mult = (1,) + tuple(self.ch_mult_)\n",
    "        block_in = self.ch * in_ch_mult[self.block_idx]\n",
    "        block_out = self.ch * self.ch_mult_[self.block_idx]\n",
    "\n",
    "        res_blocks = []\n",
    "        for _ in range(self.num_res_blocks):\n",
    "            res_blocks.append(ResnetBlock(block_in, block_out, self.act_fn))\n",
    "        block_in = block_out\n",
    "        self.block = res_blocks\n",
    "\n",
    "        self.downsample = None\n",
    "        if self.block_idx != self.num_resolutions - 1:\n",
    "            self.downsample = Downsample(block_in)\n",
    "\n",
    "    def __call__(self, h):\n",
    "        for i, res_block in enumerate(self.block):\n",
    "            h = res_block(h)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            h = self.downsample(h)\n",
    "\n",
    "        return h\n",
    "\n",
    "\n",
    "class MidBlock(nn.Module):\n",
    "    in_channels: int\n",
    "\n",
    "    def setup(self):\n",
    "        self.block_1 = ResnetBlock(\n",
    "            self.in_channels,\n",
    "            self.in_channels,\n",
    "        )\n",
    "        self.block_2 = ResnetBlock(\n",
    "            self.in_channels,\n",
    "            self.in_channels,\n",
    "        )\n",
    "\n",
    "    def __call__(self, h):\n",
    "        h = self.block_1(h)\n",
    "        h = self.block_2(h)\n",
    "\n",
    "        return h\n",
    "\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    ch: int\n",
    "    out_ch: int\n",
    "    ch_mult: tuple\n",
    "    num_res_blocks: int\n",
    "    in_channels: int\n",
    "    resolution: int\n",
    "    z_channels: int\n",
    "    double_z: bool\n",
    "    act_fn: callable = nn.gelu  # Activation function\n",
    "\n",
    "    def setup(self):\n",
    "        self.num_resolutions = len(self.ch_mult)\n",
    "\n",
    "        # downsampling\n",
    "        self.conv_in = nn.Conv(\n",
    "            self.ch,\n",
    "            kernel_size=(3, 3),\n",
    "            strides=(1, 1),\n",
    "            padding=((1, 1), (1, 1)),\n",
    "        )\n",
    "\n",
    "        curr_res = self.resolution\n",
    "        downsample_blocks = []\n",
    "\n",
    "        for i_level in range(self.num_resolutions):\n",
    "            downsample_blocks.append(\n",
    "                DownsamplingBlock(\n",
    "                    ch=self.ch,\n",
    "                    ch_mult=self.ch_mult,\n",
    "                    num_res_blocks=self.num_res_blocks,\n",
    "                    resolution=self.resolution,\n",
    "                    block_idx=i_level,\n",
    "                    act_fn=self.act_fn,\n",
    "                )\n",
    "            )\n",
    "            if i_level != self.num_resolutions - 1:\n",
    "                curr_res = curr_res // 2\n",
    "\n",
    "        self.down = downsample_blocks\n",
    "\n",
    "        # middle\n",
    "        mid_channels = self.ch * self.ch_mult[-1]\n",
    "        self.mid = MidBlock(mid_channels)\n",
    "        # end\n",
    "        self.norm_out = Normalize()\n",
    "        self.conv_out = nn.Conv(\n",
    "            self.z_channels * 2 if self.double_z else self.z_channels,\n",
    "            kernel_size=(3, 3),\n",
    "            strides=(1, 1),\n",
    "            padding=((1, 1), (1, 1)),\n",
    "        )\n",
    "\n",
    "    def __call__(self, x):\n",
    "        # downsampling\n",
    "        print(\"x :\", x.shape)\n",
    "        hs = self.conv_in(x)\n",
    "        print(\"Conv_in :\", hs.shape)\n",
    "        for block in self.down:\n",
    "            hs = block(hs)\n",
    "        print(\"Down :\", hs.shape)\n",
    "\n",
    "        # middle\n",
    "        hs = self.mid(hs)\n",
    "        print(\"Mid :\", hs.shape)\n",
    "\n",
    "        # end\n",
    "        hs = self.norm_out(hs)\n",
    "        hs = self.act_fn(hs)\n",
    "        hs = self.conv_out(hs)\n",
    "        print(\"Conv_out :\", hs.shape)\n",
    "\n",
    "        return hs\n",
    "\n",
    "\n",
    "class Upsample(nn.Module):\n",
    "    in_channels: int\n",
    "\n",
    "    def setup(self):\n",
    "        self.conv = nn.Conv(\n",
    "            self.in_channels,\n",
    "            kernel_size=(3, 3),\n",
    "            strides=(1, 1),\n",
    "            padding=((1, 1), (1, 1)),\n",
    "        )\n",
    "\n",
    "    def __call__(self, hs):\n",
    "        batch, height, width, channels = hs.shape\n",
    "        hs = jax.image.resize(\n",
    "            hs,\n",
    "            shape=(batch, height * 2, width * 2, channels),\n",
    "            method=\"bicubic\",\n",
    "        )\n",
    "        hs = self.conv(hs)\n",
    "        return hs\n",
    "\n",
    "\n",
    "class UpsamplingBlock(nn.Module):\n",
    "    ch: int\n",
    "    ch_mult: tuple\n",
    "    num_res_blocks: int\n",
    "    resolution: int\n",
    "    block_idx: int\n",
    "    act_fn: callable = nn.gelu  # Activation function\n",
    "\n",
    "    def setup(self):\n",
    "        self.ch_mult_ = self.ch_mult\n",
    "        self.num_resolutions = len(self.ch_mult_)\n",
    "\n",
    "        if self.block_idx == self.num_resolutions - 1:\n",
    "            block_in = self.ch * self.ch_mult_[-1]\n",
    "        else:\n",
    "            block_in = self.ch * self.ch_mult_[self.block_idx + 1]\n",
    "\n",
    "        block_out = self.ch * self.ch_mult_[self.block_idx]\n",
    "\n",
    "        res_blocks = []\n",
    "        for _ in range(self.num_res_blocks + 1):\n",
    "            res_blocks.append(ResnetBlock(block_in, block_out, self.act_fn))\n",
    "\n",
    "        block_in = block_out\n",
    "\n",
    "        self.block = res_blocks\n",
    "\n",
    "        self.upsample = None\n",
    "        if self.block_idx != 0:\n",
    "            self.upsample = Upsample(block_in)\n",
    "\n",
    "    def __call__(self, h):\n",
    "        for i, res_block in enumerate(self.block):\n",
    "            h = res_block(h)\n",
    "\n",
    "        if self.upsample is not None:\n",
    "            h = self.upsample(h)\n",
    "\n",
    "        return h\n",
    "\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    ch: int\n",
    "    out_ch: int\n",
    "    ch_mult: tuple\n",
    "    num_res_blocks: int\n",
    "    in_channels: int\n",
    "    resolution: int\n",
    "    z_channels: int\n",
    "    double_z: bool\n",
    "    act_fn: callable = nn.gelu  # Activation function\n",
    "\n",
    "    def setup(self):\n",
    "        self.num_resolutions = len(self.ch_mult)\n",
    "\n",
    "        block_in = self.ch * self.ch_mult[self.num_resolutions - 1]\n",
    "        curr_res = self.resolution // 2 ** (self.num_resolutions - 1)\n",
    "        self.z_shape = (1, self.z_channels, curr_res, curr_res)\n",
    "\n",
    "        # z to block_in\n",
    "        self.conv_in = nn.Conv(\n",
    "            self.ch,\n",
    "            kernel_size=(3, 3),\n",
    "            strides=(1, 1),\n",
    "            padding=((1, 1), (1, 1)),\n",
    "        )\n",
    "\n",
    "        print(\n",
    "            \"Working with z of shape {} = {} dimensions.\".format(\n",
    "                self.z_shape, np.prod(self.z_shape)\n",
    "            )\n",
    "        )\n",
    "\n",
    "        # middle\n",
    "        self.mid = MidBlock(block_in)\n",
    "\n",
    "        # upsampling\n",
    "        upsample_blocks = []\n",
    "\n",
    "        for i_level in reversed(range(self.num_resolutions)):\n",
    "            upsample_blocks.append(\n",
    "                UpsamplingBlock(\n",
    "                    ch=self.ch,\n",
    "                    ch_mult=self.ch_mult,\n",
    "                    num_res_blocks=self.num_res_blocks,\n",
    "                    resolution=self.resolution,\n",
    "                    block_idx=i_level,\n",
    "                    act_fn=self.act_fn,\n",
    "                )\n",
    "            )\n",
    "            if i_level != 0:\n",
    "                curr_res = curr_res * 2\n",
    "        self.up = list(reversed(upsample_blocks))  # reverse to get consistent order\n",
    "\n",
    "        # end\n",
    "        self.norm_out = Normalize(num_groups=5)\n",
    "        self.conv_out = nn.Conv(\n",
    "            self.out_ch,\n",
    "            kernel_size=(3, 3),\n",
    "            strides=(1, 1),\n",
    "            padding=((1, 1), (1, 1)),\n",
    "        )\n",
    "\n",
    "    def __call__(self, z):\n",
    "        # z to block_in\n",
    "        hs = self.conv_in(z)\n",
    "\n",
    "        # middle\n",
    "        hs = self.mid(hs)\n",
    "\n",
    "        # upsampling\n",
    "        for block in reversed(self.up):\n",
    "            hs = block(hs)\n",
    "\n",
    "        # end\n",
    "        hs = self.norm_out(hs)\n",
    "        hs = self.act_fn(hs)\n",
    "        hs = self.conv_out(hs)\n",
    "\n",
    "        return hs\n",
    "\n",
    "\n",
    "class AutoencoderKLModule(nn.Module):\n",
    "    ch: int\n",
    "    out_ch: int\n",
    "    ch_mult: tuple\n",
    "    num_res_blocks: int\n",
    "    in_channels: int\n",
    "    resolution: int\n",
    "    z_channels: int\n",
    "    double_z: bool\n",
    "    embed_dim: int\n",
    "    act_fn: callable = nn.gelu  # Activation function\n",
    "\n",
    "    def setup(self):\n",
    "        self.encoder = Encoder(\n",
    "            self.ch,\n",
    "            self.out_ch,\n",
    "            self.ch_mult,\n",
    "            self.num_res_blocks,\n",
    "            self.in_channels,\n",
    "            self.resolution,\n",
    "            self.z_channels,\n",
    "            self.double_z,\n",
    "            self.act_fn,\n",
    "        )\n",
    "        self.decoder = Decoder(\n",
    "            self.ch,\n",
    "            self.out_ch,\n",
    "            self.ch_mult,\n",
    "            self.num_res_blocks,\n",
    "            self.in_channels,\n",
    "            self.resolution,\n",
    "            self.z_channels,\n",
    "            self.double_z,\n",
    "            self.act_fn,\n",
    "        )\n",
    "        self.quant_conv = nn.Conv(\n",
    "            2 * self.embed_dim,\n",
    "            kernel_size=(1, 1),\n",
    "            strides=(1, 1),\n",
    "            padding=\"VALID\",\n",
    "        )\n",
    "        self.post_quant_conv = nn.Conv(\n",
    "            self.z_channels,\n",
    "            kernel_size=(1, 1),\n",
    "            strides=(1, 1),\n",
    "            padding=\"VALID\",\n",
    "        )\n",
    "\n",
    "    def encode(self, x):\n",
    "        h = self.encoder(x)\n",
    "        moments = self.quant_conv(h)\n",
    "        print(\"Moments shape :\", moments.shape)\n",
    "        posterior = tfd.MultivariateNormalDiag(\n",
    "            loc=moments[..., : self.z_channels],\n",
    "            scale_diag=moments[..., self.z_channels :],\n",
    "        )\n",
    "        print(\"Posterior :\", posterior)\n",
    "\n",
    "        return posterior\n",
    "\n",
    "    def decode(self, h):\n",
    "        h = self.post_quant_conv(h)\n",
    "        h = self.decoder(h)\n",
    "        # Image is now 64x64x5\n",
    "        q = tfd.MultivariateNormalDiag(loc=h, scale_diag=[0.01, 0.01, 0.01, 0.01, 0.01])\n",
    "        return q\n",
    "\n",
    "    def __call__(self, x, seed):\n",
    "        posterior = self.encode(x)\n",
    "        h = posterior.sample(seed=seed)\n",
    "        q = self.decode(h)\n",
    "\n",
    "        return q  # , posterior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "99bf9a39-af3c-43a1-b5b0-d5ea2bee3de9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x : (1, 64, 64, 5)\n",
      "Conv_in : (1, 64, 64, 5)\n",
      "Down : (1, 16, 16, 20)\n",
      "Mid : (1, 16, 16, 20)\n",
      "Conv_out : (1, 16, 16, 10)\n",
      "Moments shape : (1, 16, 16, 10)\n",
      "Posterior : tfp.distributions.MultivariateNormalDiag(\"MultivariateNormalDiag\", batch_shape=[1, 16, 16], event_shape=[5], dtype=float32)\n",
      "Working with z of shape (1, 5, 16, 16) = 1280 dimensions.\n"
     ]
    }
   ],
   "source": [
    "# Initializing the AutoEncoder\n",
    "Autoencoder = AutoencoderKLModule(\n",
    "    ch_mult=(1, 2, 4),\n",
    "    num_res_blocks=1,\n",
    "    double_z=True,\n",
    "    z_channels=5,\n",
    "    resolution=latent_dim,\n",
    "    in_channels=5,\n",
    "    out_ch=5,\n",
    "    ch=5,\n",
    "    embed_dim=5,\n",
    "    act_fn=act_fn,\n",
    ")\n",
    "\n",
    "params = Autoencoder.init(rng, x=batch_autoenc, seed=rng_2)\n",
    "\n",
    "# Taking 64 images of the dataset\n",
    "batch_im = next(dset)\n",
    "# Generating new keys to use them for inference\n",
    "rng_1, rng_2 = jax.random.split(rng_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "57052cfe-941b-4c51-a8eb-7109f8a7c637",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:   1 of 1 files downloaded.  \n"
     ]
    }
   ],
   "source": [
    "import wandb\n",
    "api = wandb.Api()\n",
    "\n",
    "run = api.run(\"jonnyytorres/VAE-SD/0jld85s1\")\n",
    "artifact = api.artifact('jonnyytorres/VAE-SD/0jld85s1-checkpoint:best', type='model')\n",
    "artifact_dir = artifact.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ccf4b47a-e3bf-4c09-a965-c1c06533ee31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading checkpoint for the best step\n",
    "params2 = load_checkpoint(\"checkpoint.msgpack\", params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "42688f18-5cd5-4391-abf9-02e7a4acd186",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x : (16, 64, 64, 5)\n",
      "Conv_in : (16, 64, 64, 5)\n",
      "Down : (16, 16, 16, 20)\n",
      "Mid : (16, 16, 16, 20)\n",
      "Conv_out : (16, 16, 16, 10)\n",
      "Moments shape : (16, 16, 16, 10)\n",
      "Posterior : tfp.distributions.MultivariateNormalDiag(\"MultivariateNormalDiag\", batch_shape=[16, 16, 16], event_shape=[5], dtype=float32)\n",
      "Working with z of shape (1, 5, 16, 16) = 1280 dimensions.\n"
     ]
    }
   ],
   "source": [
    "# Predicting over an example of data\n",
    "dataset_eval = input_fn(\"test\")\n",
    "test_iterator = dataset_eval.as_numpy_iterator()\n",
    "batch = next(test_iterator)\n",
    "# Taking 16 images as example\n",
    "batch = batch[:16, ...]\n",
    "\n",
    "rng, rng_1 = random.split(rng)\n",
    "# X estimated distribution\n",
    "q2 = Autoencoder.apply(params2, x=batch, seed=rng_1)\n",
    "# Sample some variables from the posterior distribution\n",
    "rng, rng_1 = random.split(rng)\n",
    "z2 = q2.sample(seed=rng_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "65ffc5c8-9d37-4b50-9d9d-8738d9d5e7cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the samples of the predicted images and their difference from the original images\n",
    "save_samples(z2, 'HSC_Second_Model.png')\n",
    "\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b5536a5f-e705-4a36-980c-28cd195aec68",
   "metadata": {},
   "outputs": [],
   "source": [
    "def norm_values_diff(orig, inf1, inf2, num_images=3):\n",
    "    min_values = []\n",
    "    max_values = []\n",
    "\n",
    "    for i in range(num_images):\n",
    "        \n",
    "        orig_img = orig[i, ...]\n",
    "        inf1_img = inf1[i, ...]\n",
    "        inf2_img = inf2[i, ...]\n",
    "\n",
    "        diff_1 = inf1_img - orig_img \n",
    "        diff_2 = inf2_img - orig_img\n",
    "\n",
    "        min_values.append(np.minimum(diff_1.mean(axis=-1).min(), diff_2.mean(axis=-1).min()))\n",
    "        max_values.append(np.minimum(diff_1.mean(axis=-1).max(), diff_2.mean(axis=-1).max()))\n",
    "\n",
    "    return [np.min(min_values), np.max(max_values)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0e989015-ba4e-4907-b6a9-960b69e1f885",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_value, max_value = norm_values_diff(batch, z, z2, num_images=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "632fa7e6-3715-4eca-8d70-677d5a2ab1a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "\n",
    "def diff_inference(orig, inf1, inf2, name):\n",
    "    \n",
    "    # Plotting the original, predicted and their differences for 8 examples\n",
    "    num_rows, num_cols = 3, 6\n",
    "\n",
    "    plt.figure(figsize=(18, 9))\n",
    "    fig, axes = plt.subplots(num_rows, num_cols, figsize=(18, 9))\n",
    "\n",
    "    # divider = make_axes_locatable(axes)\n",
    "    # cax = divider.append_axes('right', size='5%', pad=0.05)\n",
    "\n",
    "    for i, (ax1, ax2, ax3, ax4, ax5, ax6) in enumerate(zip(axes[:,0], axes[:,1], axes[:,2], axes[:,3], axes[:,4], axes[:,5])):\n",
    "        orig_img = orig[i, ...]\n",
    "        inf1_img = inf1[i, ...]\n",
    "        inf2_img = inf2[i, ...]\n",
    "\n",
    "        diff_1 = inf1_img - orig_img \n",
    "        diff_2 = inf2_img - orig_img\n",
    "\n",
    "        # Plotting original image\n",
    "        ax1.imshow(orig_img.mean(axis=-1))\n",
    "        ax1.axis(\"off\")\n",
    "        \n",
    "        # Plotting predicted image - Model 1\n",
    "        ax2.imshow(inf1_img.mean(axis=-1))\n",
    "        ax2.axis(\"off\")\n",
    "        \n",
    "        # Plotting predicted image - Model 2\n",
    "        ax3.imshow(inf2_img.mean(axis=-1))\n",
    "        ax3.axis(\"off\")\n",
    "        \n",
    "        # Plotting difference between original and predicted image - Model 1\n",
    "        im = ax4.imshow(diff_1.mean(axis=-1), vmin=min_value, vmax=max_value)\n",
    "        ax4.axis(\"off\")\n",
    "        \n",
    "        # Plotting difference between original and predicted image - Model 2\n",
    "        im = ax5.imshow(diff_2.mean(axis=-1), vmin=min_value, vmax=max_value)\n",
    "        ax5.axis(\"off\")\n",
    "\n",
    "        ax6.axis(\"off\")\n",
    "        \n",
    "        if i ==0:\n",
    "            ax1.text(2, 2, \"Original images\", verticalalignment='top', fontsize=10, color=\"white\", weight=\"bold\")\n",
    "            ax2.text(2, 2, \"Reference model\", verticalalignment='top', fontsize=10, color=\"white\", weight=\"bold\") \n",
    "            ax3.text(2, 2, \"Second tested model\", verticalalignment='top', fontsize=10, color=\"white\", weight=\"bold\") \n",
    "            ax4.text(2, 2, \"Difference original with \\n reference model images\", verticalalignment='top', fontsize=10, color=\"white\", weight=\"bold\") \n",
    "            ax5.text(2, 2, \"Difference original with \\n second model images\", verticalalignment='top', fontsize=10, color=\"white\", weight=\"bold\") \n",
    "\n",
    "    # # Add a title to the figure\n",
    "    # fig.suptitle(\n",
    "    #     \"Comparison between original and sampled images for both models\", fontsize=10, y=0.99\n",
    "    # )\n",
    "    \n",
    "    # Adding colorbar\n",
    "    # fig.colorbar(ax5.imshow(inf2_img.mean(axis=-1) - orig_img.mean(axis=-1), cax=cax, orientation='vertical'))\n",
    "        \n",
    "    # Adjust the layout of the subplots\n",
    "    fig.tight_layout()\n",
    "\n",
    "    # Create a colorbar for the \"im\" object\n",
    "    cb_ax = fig.add_axes([0.835,.02,.015,.965])\n",
    "    cbar = plt.colorbar(im, ax=[ax4, ax5], label=\"Pixel Value\", orientation=\"vertical\", aspect=120, cax=cb_ax)\n",
    "\n",
    "    # Adjust the font size of colorbar labels and ticks\n",
    "    cbar.ax.tick_params(labelsize=12)  # Adjust the fontsize as needed\n",
    "    \n",
    "    # Save plot as image\n",
    "    plt.savefig(name)\n",
    "    plt.close(fig)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "79b72051-5b73-4ec5-9542-c4484dc28b83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 1800x900 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Saving the differences between the predicted images of both models and their difference from the original images\n",
    "diff_inference(batch, z, z2, \"difference_pred_models.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a87b928e-af17-4146-a205-95dcefd0a516",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
