{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c57b5b07-e6b1-4de0-8d0a-3f685ad1534d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-11 14:47:15.546520: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-09-11 14:47:15.595909: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-09-11 14:47:16.452601: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: gpu\n",
      "Number of avaliable devices : 1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "import jax\n",
    "from jax.lib import xla_bridge\n",
    "\n",
    "# Set the CUDA_VISIBLE_DEVICES environment variable\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = str('0')\n",
    "os.environ[\"XLA_FLAGS\"] = \"--xla_gpu_cuda_data_dir=/usr/local/cuda-12.1\"\n",
    "os.environ[\"XLA_FLAGS\"] = \"--xla_gpu_force_compilation_parallelism=1\"\n",
    "\n",
    "# Checking for GPU access\n",
    "print(\"Device: {}\".format(xla_bridge.get_backend().platform))\n",
    "\n",
    "# Checking the GPU available\n",
    "gpus = jax.devices(\"gpu\")\n",
    "print(\"Number of avaliable devices : {}\".format(len(gpus)))\n",
    "\n",
    "# Ensure TF does not see GPU and grab all GPU memory.\n",
    "tf.config.set_visible_devices([], device_type=\"GPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8639909d-b061-447a-a750-39e5fcefb9b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_datasets as tfds\n",
    "from galsim_jax.datasets import cosmos\n",
    "import numpy as np\n",
    "from astropy.stats import mad_std\n",
    "import jax.numpy as jnp\n",
    "from flax import linen as nn\n",
    "\n",
    "from tensorflow_probability.substrates import jax as tfp\n",
    "tfd = tfp.distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5e9fa5e6-e055-40fd-a861-7506c294dee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import galsim as gs\n",
    "from galsim.bounds import _BoundsI\n",
    "# indices = [80100, 80101, 80102, 80103, 80104, 80105, 80106, 80107, 80108, 80203, 80252, 81005]\n",
    "indices = [80101, 80102, 80203] #, 80252, 81005]\n",
    "cat = gs.COSMOSCatalog()\n",
    "\n",
    "STAMP_SIZE = 128\n",
    "PIXEL_SCALE = 0.03\n",
    "\n",
    "def generate_examples(cat, indices):\n",
    "\n",
    "    for j in range(len(indices)):\n",
    "        i = indices[j]\n",
    "    \n",
    "        # Drawing galaxy from cosmos\n",
    "        gal = cat.makeGalaxy(i, gal_type='real', noise_pad_size=0.8*PIXEL_SCALE*STAMP_SIZE)\n",
    "        psf = gal.original_psf\n",
    "        real = gs.Convolve(psf, gal)\n",
    "        \n",
    "        print(gal.index)\n",
    "        # cosmos_gal = gs.Convolve(gal[i], gal[i].original_psf)\n",
    "    \n",
    "        cosmos_stamp = real.drawImage(\n",
    "            nx=STAMP_SIZE,\n",
    "            ny=STAMP_SIZE,\n",
    "            scale=PIXEL_SCALE,\n",
    "            method=\"no_pixel\",\n",
    "        ).array.astype(\"float32\")\n",
    "    \n",
    "        interp_factor = 1\n",
    "        padding_factor = 1\n",
    "        Nk = STAMP_SIZE * interp_factor * padding_factor\n",
    "        bounds = _BoundsI(0, Nk // 2, -Nk // 2, Nk // 2 - 1)\n",
    "    \n",
    "        imkpsf = gal.original_psf.drawKImage(\n",
    "            bounds=bounds,\n",
    "            scale=2.0\n",
    "            * np.pi\n",
    "            / (\n",
    "                STAMP_SIZE\n",
    "                * padding_factor\n",
    "                * PIXEL_SCALE\n",
    "            ),\n",
    "            recenter=False,\n",
    "        )\n",
    "    \n",
    "        kpsf = np.fft.fftshift(imkpsf.array, 0).astype(\"complex64\")\n",
    "        kpsf_real = kpsf.real\n",
    "        kpsf_imag = kpsf.imag\n",
    "    \n",
    "        # Pixel noise standard deviation\n",
    "        noise_std = np.sqrt(real.noise.getVariance())\n",
    "        \n",
    "        # Noise power spectrum\n",
    "        # from\n",
    "        # https://github.com/ml4astro/galaxy2galaxy/blob/6d8b20722a5545c8c79a19cb67c6131c061763ed/galaxy2galaxy/data_generators/galsim_utils.py#L146\n",
    "        \n",
    "        bounds = _BoundsI(0, \n",
    "                          STAMP_SIZE//2, \n",
    "                          -STAMP_SIZE//2, \n",
    "                          STAMP_SIZE//2-1\n",
    "                          )\n",
    "        imG = real.drawKImage(bounds=bounds,\n",
    "                                scale=2.*np.pi/(STAMP_SIZE * PIXEL_SCALE),\n",
    "                                recenter=False)\n",
    "        mask = ~(np.fft.fftshift(imG.array, axes=0) == 0)\n",
    "    \n",
    "        ps = real.noise._get_update_rootps((STAMP_SIZE, STAMP_SIZE), \n",
    "                                    wcs=gs.PixelScale(PIXEL_SCALE))\n",
    "    \n",
    "        rt2 = np.sqrt(2.)\n",
    "        shape = (STAMP_SIZE, STAMP_SIZE)\n",
    "        ps[0, 0] = rt2 * ps[0, 0]\n",
    "        # Then make the changes necessary for even sized arrays\n",
    "        if shape[1] % 2 == 0:  # x dimension even\n",
    "            ps[0, shape[1] // 2] = rt2 * ps[0, shape[1] // 2]\n",
    "        if shape[0] % 2 == 0:  # y dimension even\n",
    "            ps[shape[0] // 2, 0] = rt2 * ps[shape[0] // 2, 0]\n",
    "            # Both dimensions even\n",
    "            if shape[1] % 2 == 0:\n",
    "                ps[shape[0] // 2, shape[1] // 2] = rt2 * \\\n",
    "                    ps[shape[0] // 2, shape[1] // 2]\n",
    "    \n",
    "        ps = np.where(mask, np.log(ps**2), 10).astype('float32')\n",
    "        \n",
    "        yield \"%d\" % gal.index, {\n",
    "            \"image\": cosmos_stamp,\n",
    "            \"kpsf_real\": kpsf_real,\n",
    "            \"kpsf_imag\": kpsf_imag,\n",
    "            \"noise_std\": noise_std,\n",
    "            \"ps\": ps,\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "93ba5cb7-3c90-4eea-ad62-04723e40dec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "examples_fr = generate_examples(cat, indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b545ff35-db3a-4641-8d69-b409f1401b1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for ex in examples_fr:\n",
    "#     print(ex[1][\"image\"][0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4b3e0a9c-beda-46e2-a876-ef277d0f8721",
   "metadata": {},
   "outputs": [],
   "source": [
    "# examples_fr_array = np.asarray(list(examples_fr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c8dbf722-3787-49d3-b712-f6e5edaa1b85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# examples_fr_array = np.fromiter(examples_fr, dtype=float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4bdc2b73-a4ff-4ac0-a5e0-fa0d02ce3625",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86297\n",
      "Index:  86297\n",
      "86298\n",
      "Index:  86298\n",
      "86405\n",
      "Index:  86405\n"
     ]
    }
   ],
   "source": [
    "galaxies_images = []\n",
    "kpsf_real_img   = []\n",
    "kpsf_imag_img   = []\n",
    "std_list        = []\n",
    "indexes         = []\n",
    "\n",
    "def fr_examples(examples_fr):\n",
    "    for ex in examples_fr:\n",
    "        print(\"Index: \", ex[0])\n",
    "        indexes.append(ex[0])\n",
    "        \n",
    "        image_with_channel = np.expand_dims(ex[1][\"image\"], axis=-1)\n",
    "        galaxies_images.append(image_with_channel)\n",
    "\n",
    "        kpsf_real_with_channel = np.expand_dims(ex[1][\"kpsf_real\"], axis=-1)\n",
    "        kpsf_real_img.append(kpsf_real_with_channel)\n",
    "\n",
    "        kpsf_imag_with_channel = np.expand_dims(ex[1][\"kpsf_imag\"], axis=-1)\n",
    "        kpsf_imag_img.append(kpsf_imag_with_channel)\n",
    "\n",
    "        std_list.append(ex[1][\"noise_std\"])\n",
    "        \n",
    "    images = np.stack(galaxies_images, axis=0)\n",
    "    psf_real = np.stack(kpsf_real_img, axis=0)\n",
    "    psf_img = np.stack(kpsf_imag_img, axis=0)\n",
    "    std = np.stack(std_list, axis=-1)\n",
    "\n",
    "    return images, psf_real, psf_img, std, indexes\n",
    "    \n",
    "images, psf_real, psf_img, std, indexes = fr_examples(examples_fr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0fd04347-8320-49ae-a3f2-fb6a0a697304",
   "metadata": {},
   "outputs": [],
   "source": [
    "# images[0][0][0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "602b362d-7b98-4e90-bf99-3a3f00886115",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 128, 65, 1)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "psf_real.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f5d08a95-8d3e-4d8c-bd86-e7ab91764a3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "def load_galaxies(folder_path):\n",
    "    \"\"\"\n",
    "    Load all the npy files contained in the specified folder and stack them into a single NumPy array.\n",
    "\n",
    "    Parameters:\n",
    "        folder_path (str): The path to the folder containing the npy files.\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: A NumPy array containing all the data from the .npy files.\n",
    "                    The shape of the array will be (num_files, width, height, 1), where:\n",
    "                    - num_files: number of .npy files in the folder\n",
    "                    - width: width of each individual array in the .npy files\n",
    "                    - height: height of each individual array in the .npy files\n",
    "    \"\"\"\n",
    "    galaxies_data = []\n",
    "    if not os.path.exists(folder_path):\n",
    "        raise ValueError(\"The folder does not exist!\")\n",
    "\n",
    "    # Get a sorted list of .npy files in ascending order\n",
    "    sorted_files = sorted([filename for filename in os.listdir(folder_path) if filename.endswith(\".npy\")])\n",
    "\n",
    "    for filename in sorted_files:\n",
    "        file_path = os.path.join(folder_path, filename)\n",
    "        if os.path.isfile(file_path):\n",
    "            data = np.load(file_path)\n",
    "            data_with_channel = np.expand_dims(data, axis=-1)\n",
    "            galaxies_data.append(data_with_channel)\n",
    "\n",
    "    stacked_data = np.stack(galaxies_data)\n",
    "    return stacked_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d71df7b7-6f73-4ee3-8e38-7e52fdd9d1c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "galaxies_data = load_galaxies('galaxies-pres')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4044f9ea-f3cc-48b5-8d40-b95220715bbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# galaxies_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1b072f4d-7256-45cb-9f83-0ba18570f6f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# # Plotting the original, predicted and their differences for 8 examples\n",
    "# num_rows, num_cols = 3, 4\n",
    "\n",
    "# plt.figure(figsize=(10, 8))\n",
    "\n",
    "# fig, axes = plt.subplots(num_rows, num_cols, figsize=(10, 8))\n",
    "\n",
    "# for ax, z_img in zip(axes.flatten(), images):\n",
    "#     ax.imshow(z_img.mean(axis=-1))\n",
    "#     ax.axis(\"off\")\n",
    "\n",
    "# # Add a title to the figure\n",
    "# fig.suptitle(\"Original galaxies\", fontsize=12, y=0.99)\n",
    "\n",
    "# # Adjust the layout of the subplots\n",
    "# fig.tight_layout()\n",
    "\n",
    "# plt.savefig('Original_FR_galaxies_2.png')\n",
    "# plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "53997b42-cde5-409a-a2ee-829c86248218",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# fig = plt.figure(frameon=False)\n",
    "# fig.set_size_inches(3,3)\n",
    "\n",
    "# ax = plt.Axes(fig, [0., 0., 1., 1.])\n",
    "# ax.set_axis_off()\n",
    "# fig.add_axes(ax)\n",
    "\n",
    "# ax.imshow(images[9, ...].mean(axis=-1), aspect='auto')\n",
    "\n",
    "# fig.savefig('Original_galaxy_presentation.png')\n",
    "# plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9feb9736-6f6e-4ef5-ad54-13328db0cd0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# fig = plt.figure(frameon=False)\n",
    "# fig.set_size_inches(3,3)\n",
    "\n",
    "# ax = plt.Axes(fig, [0., 0., 1., 1.])\n",
    "# ax.set_axis_off()\n",
    "# fig.add_axes(ax)\n",
    "\n",
    "# ax.imshow(images[9, 32:96, 32:96, ...].mean(axis=-1), aspect='auto')\n",
    "\n",
    "# plt.savefig('Original_galaxy_presentation_2.png')\n",
    "# plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "449b4c9f-a6cb-47d2-88a2-916b46589b11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# fig = plt.figure(frameon=False)\n",
    "# fig.set_size_inches(3,3)\n",
    "\n",
    "# ax = plt.Axes(fig, [0., 0., 1., 1.])\n",
    "# ax.set_axis_off()\n",
    "# fig.add_axes(ax)\n",
    "\n",
    "# ax.imshow(images[9, 48:80, 48:80, ...].mean(axis=-1), aspect='auto')\n",
    "\n",
    "# plt.savefig('Original_galaxy_presentation_3.png')\n",
    "# plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4ae826e2-e70e-409e-99a3-a68dcbf4d2f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x : (1, 128, 128, 1)\n",
      "Conv_in : (1, 128, 128, 1)\n",
      "Down : (1, 32, 32, 4)\n",
      "Mid : (1, 32, 32, 4)\n",
      "Conv_out : (1, 32, 32, 2)\n",
      "Moments shape : (1, 32, 32, 2)\n",
      "Posterior : tfp.distributions.MultivariateNormalDiag(\"MultivariateNormalDiag\", batch_shape=[1, 32, 32], event_shape=[1], dtype=float32)\n",
      "Working with z of shape (1, 1, 32, 32) = 1024 dimensions.\n"
     ]
    }
   ],
   "source": [
    "from galsim_jax.dif_models import AutoencoderKLModule\n",
    "\n",
    "# Generating a random key for JAX\n",
    "rng, rng_2 = jax.random.PRNGKey(0), jax.random.PRNGKey(1)\n",
    "# Size of the input to initialize the encoder parameters\n",
    "batch_autoenc = jnp.ones((1, 128, 128, 1))\n",
    "\n",
    "latent_dim = 128\n",
    "act_fn = nn.gelu\n",
    "\n",
    "# Initializing the AutoEncoder\n",
    "Autoencoder = AutoencoderKLModule(\n",
    "    ch_mult=(1, 2, 4),\n",
    "    num_res_blocks=2,\n",
    "    double_z=True,\n",
    "    z_channels=1,\n",
    "    resolution=latent_dim,\n",
    "    in_channels=1,\n",
    "    out_ch=1,\n",
    "    ch=1,\n",
    "    embed_dim=1,\n",
    "    act_fn=act_fn,\n",
    ")\n",
    "\n",
    "params = Autoencoder.init(rng, x=batch_autoenc, seed=rng_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3f1bb8f9-96ae-483d-9ab9-33df6d74c14f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:   1 of 1 files downloaded.  \n"
     ]
    }
   ],
   "source": [
    "import wandb\n",
    "api = wandb.Api()\n",
    "\n",
    "run = api.run(\"jonnyytorres/VAE-SD/iebszvhp\")\n",
    "artifact = api.artifact('jonnyytorres/VAE-SD/iebszvhp-checkpoint:best', type='model')\n",
    "artifact_dir = artifact.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a91de8ad-90bf-4540-a0c6-001c53e04557",
   "metadata": {},
   "outputs": [],
   "source": [
    "from flax.serialization import to_state_dict, msgpack_serialize, from_bytes\n",
    "\n",
    "def load_checkpoint(ckpt_file, state):\n",
    "    \"\"\"Loads the best Wandb checkpoint.\"\"\"\n",
    "    # artifact = wandb.use_artifact(f\"artifacts/{run.id}-checkpoint:v72/\")\n",
    "    artifact_dir = f\"artifacts/{run.id}-checkpoint:best/\"\n",
    "    ckpt_path = os.path.join(artifact_dir, ckpt_file)\n",
    "    with open(ckpt_path, \"rb\") as data_file:\n",
    "        byte_data = data_file.read()\n",
    "    return from_bytes(state, byte_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "268c3bd2-3c2d-4df8-a349-314f57b9e7ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading checkpoint for the best step\n",
    "# wandb.init()\n",
    "params = load_checkpoint(\"checkpoint.msgpack\", params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fca8d455-f605-441e-9d03-cd3a3627d590",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_samples(z, name):\n",
    "    # Plotting 16 images of the estimated shape of galaxies\n",
    "    num_rows, num_cols = 3, 4\n",
    "\n",
    "    fig, axes = plt.subplots(num_rows, num_cols, figsize=(10, 8))\n",
    "\n",
    "    for ax, z_img in zip(axes.flatten(), z):\n",
    "        ax.imshow(tf.math.reduce_mean(z_img, axis=-1))\n",
    "        # ax.imshow(z_img.mean(axis=-1))\n",
    "        ax.axis(\"off\")\n",
    "\n",
    "    # Add a title to the figure\n",
    "    fig.suptitle(\"Samples of predicted galaxies\", fontsize=16)\n",
    "\n",
    "    # Adjust the layout of the subplots\n",
    "    fig.tight_layout()\n",
    "\n",
    "    plt.savefig(name)\n",
    "    plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9aa610c0-11bc-4ced-904d-d36575bdf93c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x : (3, 128, 128, 1)\n",
      "Conv_in : (3, 128, 128, 1)\n",
      "Down : (3, 32, 32, 4)\n",
      "Mid : (3, 32, 32, 4)\n",
      "Conv_out : (3, 32, 32, 2)\n",
      "Moments shape : (3, 32, 32, 2)\n",
      "Posterior : tfp.distributions.MultivariateNormalDiag(\"MultivariateNormalDiag\", batch_shape=[3, 32, 32], event_shape=[1], dtype=float32)\n",
      "Working with z of shape (1, 1, 32, 32) = 1024 dimensions.\n"
     ]
    }
   ],
   "source": [
    "from galsim_jax.convolution import convolve_kpsf\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "# Predicting over an example of data\n",
    "\n",
    "x = images\n",
    "kpsf_real = psf_real \n",
    "kpsf_imag = psf_img\n",
    "kpsf = kpsf_real + 1j*kpsf_imag\n",
    "std = std.reshape((-1, 1, 1, 1))\n",
    "\n",
    "# Generating a random key for JAX\n",
    "rng, rng_2 = jax.random.PRNGKey(0), jax.random.PRNGKey(1)\n",
    "\n",
    "rng, rng_1 = jax.random.split(rng)\n",
    "# X estimated distribution\n",
    "q = Autoencoder.apply(params, x=x, seed=rng_1)\n",
    "z = q\n",
    "\n",
    "# Saving the samples of the predicted images and their difference from the original images\n",
    "# save_samples(z, 'Autoencoder_samples.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9856e316-bf9d-445c-8a5f-d2ac6c390147",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 128, 128)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q[..., 0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0b1ee711-f48e-416d-beae-9d86ffec26c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 128, 65)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kpsf[..., 0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1c094135-48d3-4c9a-9cc4-5f446254430b",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = jax.vmap(convolve_kpsf)(q[..., 0], kpsf[..., 0])\n",
    "\n",
    "p = tf.expand_dims(p, axis=-1)\n",
    "\n",
    "z = p\n",
    "\n",
    "# Saving the samples of the predicted images and their difference from the original images\n",
    "# save_samples(z, 'Convolve_samples.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "82945d8b-16ef-4563-a7e2-f28e4935076f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting array into float32\n",
    "std = np.float32(std)\n",
    "\n",
    "p = tfd.MultivariateNormalDiag(loc=p, scale_diag=std)\n",
    "\n",
    "pred_model_2 = p.sample(seed=rng_1)\n",
    "\n",
    "# Saving the samples of the predicted images and their difference from the original images\n",
    "# save_samples(pred_model_2, 'MNDist_samples.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8855ded7-03a1-4e84-a69e-f6307e6a948c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 128, 128, 1)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "galaxies_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8d0828f9-0824-40aa-bce3-bea9671bef0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = tfd.MultivariateNormalDiag(loc=galaxies_data, scale_diag=std)\n",
    "\n",
    "pred_model_1 = p.sample(seed=rng_1)\n",
    "\n",
    "# Saving the samples of the predicted images and their difference from the original images\n",
    "# save_samples(pred_model_1, 'MNDist_samples_FR.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "26193124-85de-4ae6-8ac5-ec559b0530d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def norm_values_diff(orig, inf1, inf2, num_images=3):\n",
    "    min_values = []\n",
    "    max_values = []\n",
    "\n",
    "    for i in range(num_images):\n",
    "        \n",
    "        orig_img = orig[i, ...]\n",
    "        inf1_img = inf1[i, ...]\n",
    "        inf2_img = inf2[i, ...]\n",
    "\n",
    "        diff_1 = inf1_img - orig_img \n",
    "        diff_2 = inf2_img - orig_img\n",
    "\n",
    "        min_values.append(np.minimum(diff_1.mean(axis=-1).min(), diff_2.mean(axis=-1).min()))\n",
    "        max_values.append(np.minimum(diff_1.mean(axis=-1).max(), diff_2.mean(axis=-1).max()))\n",
    "\n",
    "    return [np.min(min_values), np.max(max_values)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "dad552d2-757c-4336-ab0a-4fb91193db01",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_value, max_value = norm_values_diff(images, pred_model_1, pred_model_2, num_images=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6d5f4e17-16a7-4fbd-9396-5d7558d5d6d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "def diff_inference(orig, inf1, inf2, name):\n",
    "     \n",
    "    # Plotting the original, predicted and their differences for 8 examples\n",
    "    num_rows, num_cols = 3, 6\n",
    "\n",
    "    plt.figure(figsize=(18, 9))\n",
    "    fig, axes = plt.subplots(num_rows, num_cols, figsize=(18, 9))\n",
    "\n",
    "    for i, (ax1, ax2, ax3, ax4, ax5, ax6) in enumerate(zip(axes[:,0], axes[:,1], axes[:,2], axes[:,3], axes[:,4], axes[:,5])):\n",
    "        orig_img = orig[i, ...]\n",
    "        inf1_img = inf1[i, ...]\n",
    "        inf2_img = inf2[i, ...]\n",
    "\n",
    "        diff_1 = inf1_img - orig_img \n",
    "        diff_2 = inf2_img - orig_img\n",
    "\n",
    "        # Plotting original image\n",
    "        ax1.imshow(orig_img.mean(axis=-1))\n",
    "        ax1.axis(\"off\")\n",
    "        \n",
    "        # Plotting predicted image - Model 1\n",
    "        ax2.imshow(inf1_img.mean(axis=-1))\n",
    "        ax2.axis(\"off\")\n",
    "        \n",
    "        # Plotting predicted image - Model 2\n",
    "        ax3.imshow(inf2_img.mean(axis=-1))\n",
    "        ax3.axis(\"off\")\n",
    "        \n",
    "        # Plotting difference between original and predicted image - Model 1\n",
    "        im = ax4.imshow(diff_1.mean(axis=-1), vmin=min_value, vmax=max_value)\n",
    "        ax4.axis(\"off\")\n",
    "        \n",
    "        # Plotting difference between original and predicted image - Model 2\n",
    "        im = ax5.imshow(diff_2.mean(axis=-1), vmin=min_value, vmax=max_value)\n",
    "        ax5.axis(\"off\")\n",
    "\n",
    "        ax6.axis(\"off\")\n",
    "        \n",
    "        if i ==0:\n",
    "            ax1.text(2, 2, \"Original images\", verticalalignment='top', fontsize=10, color=\"white\", weight=\"bold\")\n",
    "            ax2.text(2, 2, \"Reference model\", verticalalignment='top', fontsize=10, color=\"white\", weight=\"bold\") \n",
    "            ax3.text(2, 2, \"State-of-the-art model\", verticalalignment='top', fontsize=10, color=\"white\", weight=\"bold\") \n",
    "            ax4.text(2, 2, \"Difference original with \\n reference model images\", verticalalignment='top', fontsize=10, color=\"white\", weight=\"bold\") \n",
    "            ax5.text(2, 2, \"Difference original with \\n State-of-the-art images\", verticalalignment='top', fontsize=10, color=\"white\", weight=\"bold\") \n",
    "\n",
    "    # Add a title to the figure\n",
    "    # fig.suptitle(\n",
    "    #     \"Comparison between original and predicted images for both models\", fontsize=12, y=0.99\n",
    "    # )\n",
    "            \n",
    "    # Adjust the layout of the subplots\n",
    "    fig.tight_layout()\n",
    "\n",
    "    # cmap = mpl.cm.cool\n",
    "    # norm = mpl.colors.Normalize(vmin=min_value, vmax=max_value)\n",
    "\n",
    "    # Create a colorbar for the \"im\" object\n",
    "    cb_ax = fig.add_axes([0.835,.015,.015,.965])\n",
    "    cbar = plt.colorbar(im, ax=[ax4, ax5], label=\"Pixel Value\", orientation=\"vertical\", aspect=120, cax=cb_ax)\n",
    "\n",
    "    # Adjust the font size of colorbar labels and ticks\n",
    "    cbar.ax.tick_params(labelsize=12)  # Adjust the fontsize as needed\n",
    "\n",
    "    # # Save plot as image\n",
    "    plt.savefig(name)\n",
    "    plt.close(fig)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5f21bd52-3a33-40d4-a8ae-08fe3896f1e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 1800x900 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Saving the differences between the predicted images of both models and their difference from the original images\n",
    "diff_inference(images, pred_model_1, pred_model_2, \"difference_best_model.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e41d8a88-024a-40ce-adb6-08cb05ca4f59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x : (1, 128, 128, 1)\n",
      "Conv_in : (1, 128, 128, 1)\n",
      "Down : (1, 16, 16, 8)\n",
      "Mid : (1, 16, 16, 8)\n",
      "Conv_out : (1, 16, 16, 2)\n",
      "Moments shape : (1, 16, 16, 2)\n",
      "Posterior : tfp.distributions.MultivariateNormalDiag(\"MultivariateNormalDiag\", batch_shape=[1, 16, 16], event_shape=[1], dtype=float32)\n",
      "Working with z of shape (1, 1, 16, 16) = 256 dimensions.\n"
     ]
    }
   ],
   "source": [
    "# Generating a random key for JAX\n",
    "rng, rng_2 = jax.random.PRNGKey(0), jax.random.PRNGKey(1)\n",
    "# Size of the input to initialize the encoder parameters\n",
    "batch_autoenc = jnp.ones((1, 128, 128, 1))\n",
    "\n",
    "latent_dim = 128\n",
    "act_fn = nn.gelu\n",
    "\n",
    "# Initializing the AutoEncoder\n",
    "Autoencoder2 = AutoencoderKLModule(\n",
    "    ch_mult=(1, 2, 4, 8),\n",
    "    num_res_blocks=2,\n",
    "    double_z=True,\n",
    "    z_channels=1,\n",
    "    resolution=latent_dim,\n",
    "    in_channels=1,\n",
    "    out_ch=1,\n",
    "    ch=1,\n",
    "    embed_dim=1,\n",
    "    act_fn=act_fn,\n",
    ")\n",
    "\n",
    "params2 = Autoencoder2.init(rng, x=batch_autoenc, seed=rng_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9d86adb3-2318-44c0-ba0f-f77aa004dbbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:   1 of 1 files downloaded.  \n"
     ]
    }
   ],
   "source": [
    "run = api.run(\"jonnyytorres/VAE-SD/5rxwcd2b\")\n",
    "artifact = api.artifact('jonnyytorres/VAE-SD/5rxwcd2b-checkpoint:best', type='model')\n",
    "artifact_dir = artifact.download()\n",
    "\n",
    "# Loading checkpoint for the best step\n",
    "params2 = load_checkpoint(\"checkpoint.msgpack\", params2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4ee22d4a-d3f8-4b98-ba3b-8d3e737ddda1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x : (3, 128, 128, 1)\n",
      "Conv_in : (3, 128, 128, 1)\n",
      "Down : (3, 16, 16, 8)\n",
      "Mid : (3, 16, 16, 8)\n",
      "Conv_out : (3, 16, 16, 2)\n",
      "Moments shape : (3, 16, 16, 2)\n",
      "Posterior : tfp.distributions.MultivariateNormalDiag(\"MultivariateNormalDiag\", batch_shape=[3, 16, 16], event_shape=[1], dtype=float32)\n",
      "Working with z of shape (1, 1, 16, 16) = 256 dimensions.\n"
     ]
    }
   ],
   "source": [
    "# Generating a random key for JAX\n",
    "rng, rng_2 = jax.random.PRNGKey(0), jax.random.PRNGKey(1)\n",
    "\n",
    "rng, rng_1 = jax.random.split(rng)\n",
    "# X estimated distribution\n",
    "q2 = Autoencoder2.apply(params2, x=x, seed=rng_1)\n",
    "z2 = q2\n",
    "\n",
    "p2 = jax.vmap(convolve_kpsf)(q2[..., 0], kpsf[..., 0])\n",
    "\n",
    "p2 = tf.expand_dims(p2, axis=-1)\n",
    "\n",
    "z2 = p2\n",
    "\n",
    "p2 = tfd.MultivariateNormalDiag(loc=p2, scale_diag=std)\n",
    "\n",
    "model_bottleneck_16 = p2.sample(seed=rng_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3b6898bb-f730-4714-b694-e4ff04db4d64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x : (1, 128, 128, 1)\n",
      "Conv_in : (1, 128, 128, 1)\n",
      "Down : (1, 8, 8, 16)\n",
      "Mid : (1, 8, 8, 16)\n",
      "Conv_out : (1, 8, 8, 2)\n",
      "Moments shape : (1, 8, 8, 2)\n",
      "Posterior : tfp.distributions.MultivariateNormalDiag(\"MultivariateNormalDiag\", batch_shape=[1, 8, 8], event_shape=[1], dtype=float32)\n",
      "Working with z of shape (1, 1, 8, 8) = 64 dimensions.\n"
     ]
    }
   ],
   "source": [
    "# Generating a random key for JAX\n",
    "rng, rng_2 = jax.random.PRNGKey(0), jax.random.PRNGKey(1)\n",
    "# Size of the input to initialize the encoder parameters\n",
    "batch_autoenc = jnp.ones((1, 128, 128, 1))\n",
    "\n",
    "latent_dim = 128\n",
    "act_fn = nn.gelu\n",
    "\n",
    "# Initializing the AutoEncoder\n",
    "Autoencoder3 = AutoencoderKLModule(\n",
    "    ch_mult=(1, 2, 4, 8, 16),\n",
    "    num_res_blocks=2,\n",
    "    double_z=True,\n",
    "    z_channels=1,\n",
    "    resolution=latent_dim,\n",
    "    in_channels=1,\n",
    "    out_ch=1,\n",
    "    ch=1,\n",
    "    embed_dim=1,\n",
    "    act_fn=act_fn,\n",
    ")\n",
    "\n",
    "params3 = Autoencoder3.init(rng, x=batch_autoenc, seed=rng_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "91063c85-86db-4085-b2cb-445c5109d7d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:   1 of 1 files downloaded.  \n"
     ]
    }
   ],
   "source": [
    "run = api.run(\"jonnyytorres/VAE-SD/gakxodml\")\n",
    "artifact = api.artifact('jonnyytorres/VAE-SD/gakxodml-checkpoint:best', type='model')\n",
    "artifact_dir = artifact.download()\n",
    "\n",
    "# Loading checkpoint for the best step\n",
    "params3 = load_checkpoint(\"checkpoint.msgpack\", params3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4612ae10-da6c-4088-ab95-a57026fa6c35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x : (3, 128, 128, 1)\n",
      "Conv_in : (3, 128, 128, 1)\n",
      "Down : (3, 8, 8, 16)\n",
      "Mid : (3, 8, 8, 16)\n",
      "Conv_out : (3, 8, 8, 2)\n",
      "Moments shape : (3, 8, 8, 2)\n",
      "Posterior : tfp.distributions.MultivariateNormalDiag(\"MultivariateNormalDiag\", batch_shape=[3, 8, 8], event_shape=[1], dtype=float32)\n",
      "Working with z of shape (1, 1, 8, 8) = 64 dimensions.\n"
     ]
    }
   ],
   "source": [
    "# Generating a random key for JAX\n",
    "rng, rng_2 = jax.random.PRNGKey(0), jax.random.PRNGKey(1)\n",
    "\n",
    "rng, rng_1 = jax.random.split(rng)\n",
    "# X estimated distribution\n",
    "q3 = Autoencoder3.apply(params3, x=x, seed=rng_1)\n",
    "z3 = q3\n",
    "\n",
    "p3 = jax.vmap(convolve_kpsf)(q3[..., 0], kpsf[..., 0])\n",
    "\n",
    "p3 = tf.expand_dims(p3, axis=-1)\n",
    "\n",
    "z3 = p3\n",
    "\n",
    "p3 = tfd.MultivariateNormalDiag(loc=p3, scale_diag=std)\n",
    "\n",
    "model_bottleneck_8 = p3.sample(seed=rng_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "813b6d67-cfce-4be5-9328-737b799112eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def norm_values_two_diff(orig, inf1, inf2, inf3, num_images=3):\n",
    "    min_values = []\n",
    "    max_values = []\n",
    "\n",
    "    for i in range(num_images):\n",
    "        \n",
    "        orig_img = orig[i, ...]\n",
    "        inf1_img = inf1[i, ...]\n",
    "        inf2_img = inf2[i, ...]\n",
    "        inf3_img = inf3[i, ...]\n",
    "\n",
    "        diff_1 = inf1_img - orig_img \n",
    "        diff_2 = inf2_img - orig_img\n",
    "        diff_3 = inf3_img - orig_img\n",
    "\n",
    "        min_values.append(np.minimum(np.minimum(diff_1.mean(axis=-1).min(), diff_2.mean(axis=-1).min()), diff_3.mean(axis=-1).min())) \n",
    "        max_values.append(np.minimum(np.minimum(diff_1.mean(axis=-1).max(), diff_2.mean(axis=-1).max()), diff_3.mean(axis=-1).max()))\n",
    "\n",
    "    return [np.min(min_values), np.max(max_values)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2e2725b2-e750-4eef-a9d4-5b557545559f",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_value, max_value = norm_values_two_diff(images, pred_model_2, model_bottleneck_16, model_bottleneck_8, num_images=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "28e29af9-38bf-4278-983a-eac3986ff22a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def diff_two_inference(orig, inf1, inf2, inf3, name):\n",
    "\n",
    "    # Plotting the original, predicted and their differences for 8 examples\n",
    "    num_rows, num_cols = 3, 8\n",
    "\n",
    "    plt.figure(figsize=(24, 9))\n",
    "    fig, axes = plt.subplots(num_rows, num_cols, figsize=(24, 9))\n",
    "\n",
    "    for i, (ax1, ax2, ax3, ax4, ax5, ax6, ax7, ax8) in enumerate(zip(axes[:,0], axes[:,1], axes[:,2], axes[:,3], axes[:,4], axes[:,5], axes[:,6], axes[:,7])):\n",
    "        orig_img = orig[i, ...]\n",
    "        inf1_img = inf1[i, ...]\n",
    "        inf2_img = inf2[i, ...]\n",
    "        inf3_img = inf3[i, ...]\n",
    "\n",
    "        diff_1 = inf1_img - orig_img \n",
    "        diff_2 = inf2_img - orig_img\n",
    "        diff_3 = inf3_img - orig_img\n",
    "\n",
    "        # Plotting original image\n",
    "        ax1.imshow(orig_img.mean(axis=-1))\n",
    "        ax1.axis(\"off\")\n",
    "        \n",
    "        # Plotting predicted image - Model 1\n",
    "        ax2.imshow(inf1_img.mean(axis=-1))\n",
    "        ax2.axis(\"off\")\n",
    "        \n",
    "        # Plotting predicted image - Model 2\n",
    "        ax3.imshow(inf2_img.mean(axis=-1))\n",
    "        ax3.axis(\"off\")\n",
    "\n",
    "        # Plotting predicted image - Model 2\n",
    "        ax4.imshow(inf3_img.mean(axis=-1))\n",
    "        ax4.axis(\"off\")\n",
    "        \n",
    "        # Plotting difference between original and predicted image - Model 1\n",
    "        im = ax5.imshow(diff_1.mean(axis=-1), vmin = min_value, vmax = max_value)\n",
    "        ax5.axis(\"off\")\n",
    "        \n",
    "        # Plotting difference between original and predicted image - Model 2\n",
    "        im = ax6.imshow(diff_2.mean(axis=-1), vmin = min_value, vmax = max_value)\n",
    "        ax6.axis(\"off\")\n",
    "\n",
    "        # Plotting difference between original and predicted image - Model 2\n",
    "        im = ax7.imshow(diff_3.mean(axis=-1), vmin = min_value, vmax = max_value)\n",
    "        ax7.axis(\"off\")\n",
    "\n",
    "        ax8.axis(\"off\")\n",
    "        \n",
    "        if i ==0:\n",
    "            ax1.text(2, 2, \"Original images\", verticalalignment='top', fontsize=10, color=\"white\", weight=\"bold\")\n",
    "            ax2.text(2, 2, \"Bottleneck size = $32^2$\", verticalalignment='top', fontsize=10, color=\"white\", weight=\"bold\") \n",
    "            ax3.text(2, 2, \"Bottleneck size = $16^2$\", verticalalignment='top', fontsize=10, color=\"white\", weight=\"bold\")\n",
    "            ax4.text(2, 2, \"Bottleneck size = $8^2$\", verticalalignment='top', fontsize=10, color=\"white\", weight=\"bold\") \n",
    "            ax5.text(2, 2, \"Difference original with \\n$32^2$ Bottleneck size images\", verticalalignment='top', fontsize=10, color=\"white\", weight=\"bold\") \n",
    "            ax6.text(2, 2, \"Difference original with \\n$16^2$ Bottleneck size images\", verticalalignment='top', fontsize=10, color=\"white\", weight=\"bold\") \n",
    "            ax7.text(2, 2, \"Difference original with \\n$8^2$ Bottleneck size images\", verticalalignment='top', fontsize=10, color=\"white\", weight=\"bold\") \n",
    "\n",
    "    # Add a title to the figure\n",
    "    # fig.suptitle(\n",
    "    #     \"Comparison between original and predicted images for both models\", fontsize=12, y=0.99\n",
    "    # )\n",
    "\n",
    "    # Adjust the layout of the subplots\n",
    "    fig.tight_layout()\n",
    "\n",
    "    # Create a colorbar for the \"im\" object\n",
    "    cb_ax = fig.add_axes([0.885,.024,.015,.95])\n",
    "    cbar = plt.colorbar(im, ax=[ax5, ax6, ax7], label=\"Pixel Value\", orientation=\"vertical\", aspect=120, cax=cb_ax)\n",
    "\n",
    "    # Adjust the font size of colorbar labels and ticks\n",
    "    cbar.ax.tick_params(labelsize=12)  # Adjust the fontsize as needed\n",
    "\n",
    "    # print(min_value, max_value)\n",
    "    \n",
    "    # # Save plot as image\n",
    "    plt.savefig(name)\n",
    "    plt.close(fig)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "be0aeac8-ff35-4cff-9909-8a413042ea64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 2400x900 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Saving the differences between the predicted images of the previous model and their difference from the original images\n",
    "diff_two_inference(images, pred_model_2, model_bottleneck_16, model_bottleneck_8,  \"difference_depth_model_presentation.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "9c9631b1-717d-43f3-8c85-48120fe6da70",
   "metadata": {},
   "outputs": [],
   "source": [
    "def norm_values_one_diff(orig, inf1, num_images=3):\n",
    "    min_values = []\n",
    "    max_values = []\n",
    "\n",
    "    for i in range(num_images):\n",
    "        \n",
    "        orig_img = orig[i, ...]\n",
    "        inf1_img = inf1[i, ...]\n",
    "\n",
    "        diff_1 = inf1_img - orig_img \n",
    "\n",
    "        min_values.append(diff_1.mean(axis=-1).min())\n",
    "        max_values.append(diff_1.mean(axis=-1).max())\n",
    "\n",
    "    return [np.min(min_values), np.max(max_values)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "e1ff16d5-3022-4ce5-a233-b12293ecd774",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_value, max_value = norm_values_one_diff(images, pred_model_1, num_images=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f38f89a-6d5c-4edb-97ea-cbfd698072d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "1177174d-06a9-45f9-9297-9eb9b5438e0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def diff_one_inference(orig, inf1, name):\n",
    "    \n",
    "    # Plotting the original, predicted and their differences for 8 examples\n",
    "    num_rows, num_cols = 3, 4\n",
    "\n",
    "    plt.figure(figsize=(12, 9))\n",
    "    fig, axes = plt.subplots(num_rows, num_cols, figsize=(12, 9))\n",
    "\n",
    "    for i, (ax1, ax2, ax3, ax4) in enumerate(zip(axes[:, 0], axes[:, 1], axes[:, 2], axes[:, 3])):\n",
    "        orig_img = orig[i, ...]\n",
    "        inf1_img = inf1[i, ...]\n",
    "\n",
    "        diff_1 = inf1_img - orig_img \n",
    "\n",
    "        # Plotting original image\n",
    "        ax1.imshow(orig_img.mean(axis=-1))\n",
    "        ax1.axis(\"off\")\n",
    "        \n",
    "        # Plotting predicted image - Model 1\n",
    "        ax2.imshow(inf1_img.mean(axis=-1))\n",
    "        ax2.axis(\"off\")\n",
    "        \n",
    "       # Plotting difference between original and predicted image - Model 1\n",
    "        im = ax3.imshow(diff_1.mean(axis=-1), vmin=min_value, vmax=max_value)\n",
    "        ax3.axis(\"off\")\n",
    "\n",
    "        ax4.axis(\"off\")\n",
    "        \n",
    "        if i ==0:\n",
    "            ax1.set_title('Original images', fontsize=10)\n",
    "            ax2.set_title('Previous model', fontsize=10)\n",
    "            ax3.set_title('Difference previous model', fontsize=10)\n",
    "\n",
    "    # # Add a title to the figure\n",
    "    # fig.suptitle(\n",
    "    #     \"Comparison between original and predicted images for the previous model\", fontsize=10, y=0.99\n",
    "    # )\n",
    "\n",
    "    # Adjust the layout of the subplots\n",
    "    fig.tight_layout()\n",
    "\n",
    "    # Create a colorbar for the \"im\" object\n",
    "    cb_ax = fig.add_axes([0.755,.02,.015,.94])\n",
    "    cbar = plt.colorbar(im, ax=ax3, label=\"Pixel Value\", orientation=\"vertical\", aspect=120, cax=cb_ax)\n",
    "\n",
    "    # Adjust the font size of colorbar labels and ticks\n",
    "    cbar.ax.tick_params(labelsize=12)  # Adjust the fontsize as needed\n",
    "\n",
    "    # Save plot as image\n",
    "    plt.savefig(name)\n",
    "    plt.close(fig)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "ac050a64-7ba6-4aa8-9f9f-1ba028a056f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x900 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Saving the differences between the predicted images of the previous model and their difference from the original images\n",
    "diff_one_inference(images, pred_model_1, \"difference_prev_model.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "2bb94a80-28eb-461e-be28-826a09a7524a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def diff_one_inference_2(orig, inf1, name):\n",
    "    \n",
    "    # Plotting the original, predicted and their differences for 8 examples\n",
    "    num_rows, num_cols = 5, 3\n",
    "\n",
    "    plt.figure(figsize=(6, 10.5))\n",
    "    fig, axes = plt.subplots(num_rows, num_cols, figsize=(6, 10.5))\n",
    "\n",
    "    for i, (ax1, ax2, ax3) in enumerate(zip(axes[:, 0], axes[:, 1], axes[:, 2])):\n",
    "        orig_img = orig[i, ...]\n",
    "        inf1_img = inf1[i, ...]\n",
    "\n",
    "        # Plotting original image\n",
    "        ax1.imshow(orig_img.mean(axis=-1))\n",
    "        ax1.axis(\"off\")\n",
    "        \n",
    "        # Plotting predicted image - Model 1\n",
    "        ax2.imshow(inf1_img.mean(axis=-1))\n",
    "        ax2.axis(\"off\")\n",
    "        \n",
    "       # Plotting difference between original and predicted image - Model 1\n",
    "        ax3.imshow(inf1_img.mean(axis=-1) - orig_img.mean(axis=-1))\n",
    "        ax3.axis(\"off\")\n",
    "        \n",
    "        if i ==0:\n",
    "            ax1.set_title('Original images', fontsize=8)\n",
    "            ax2.set_title('Prediction model', fontsize=8)\n",
    "            ax3.set_title('Difference model', fontsize=8)\n",
    "\n",
    "    # Add a title to the figure\n",
    "    fig.suptitle(\n",
    "        \"Comparison between original and predicted images for the prediction model\", fontsize=10, y=0.99\n",
    "    )\n",
    "\n",
    "    # Adjust the layout of the subplots\n",
    "    fig.tight_layout()\n",
    "\n",
    "    # Save plot as image\n",
    "    plt.savefig(name)\n",
    "    plt.close(fig)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a741145-4d4d-42c5-829b-226c52675118",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the differences between the predicted images of the new model and their difference from the original images\n",
    "diff_one_inference_2(images, pred_model_2, \"difference_new_model.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70f37cb9-c818-49b9-98d2-420d63aab5e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig = plt.figure(frameon=False)\n",
    "fig.set_size_inches(3,3)\n",
    "\n",
    "ax = plt.Axes(fig, [0., 0., 1., 1.])\n",
    "ax.set_axis_off()\n",
    "fig.add_axes(ax)\n",
    "\n",
    "ax.imshow(pred_model_2[2, ...].mean(axis=-1), aspect='auto')\n",
    "\n",
    "fig.savefig('Pred_galaxy_presentation.png')\n",
    "plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d1a53f2-20f6-4f91-a6af-20b6fb98ec61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating a random key for JAX\n",
    "rng, rng_2 = jax.random.PRNGKey(0), jax.random.PRNGKey(1)\n",
    "# Size of the input to initialize the encoder parameters\n",
    "batch_autoenc = jnp.ones((1, 128, 128, 1))\n",
    "\n",
    "latent_dim = 128\n",
    "act_fn = nn.gelu\n",
    "\n",
    "# Initializing the AutoEncoder\n",
    "Autoencoder = AutoencoderKLModule(\n",
    "    ch_mult=(1, 2, 4),\n",
    "    num_res_blocks=2,\n",
    "    double_z=True,\n",
    "    z_channels=1,\n",
    "    resolution=latent_dim,\n",
    "    in_channels=1,\n",
    "    out_ch=1,\n",
    "    ch=1,\n",
    "    embed_dim=1,\n",
    "    act_fn=act_fn,\n",
    ")\n",
    "\n",
    "params = Autoencoder.init(rng, x=batch_autoenc, seed=rng_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ade57b52-1457-4f3c-bbf2-424e4f07549a",
   "metadata": {},
   "outputs": [],
   "source": [
    "run = api.run(\"jonnyytorres/VAE-SD/iebszvhp\")\n",
    "artifact = api.artifact('jonnyytorres/VAE-SD/iebszvhp-checkpoint:best', type='model')\n",
    "artifact_dir = artifact.download()\n",
    "\n",
    "# Loading checkpoint for the best step\n",
    "params = load_checkpoint(\"checkpoint.msgpack\", params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7d4bb0f-8aac-4a75-b9c5-1cb011c95f18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating a random key for JAX\n",
    "rng, rng_2 = jax.random.PRNGKey(0), jax.random.PRNGKey(1)\n",
    "\n",
    "rng, rng_1 = jax.random.split(rng)\n",
    "# X estimated distribution\n",
    "q = Autoencoder.apply(params, x=x, seed=rng_1)\n",
    "z = q\n",
    "\n",
    "# Saving the samples of the predicted images and their difference from the original images\n",
    "save_samples(z, 'Autoencoder_samples_best.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e9ec2ea-317a-45d4-95b2-72f501d0626e",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = jax.vmap(convolve_kpsf)(q[..., 0], kpsf[..., 0])\n",
    "\n",
    "p = tf.expand_dims(p, axis=-1)\n",
    "\n",
    "z = p\n",
    "\n",
    "# Saving the samples of the predicted images and their difference from the original images\n",
    "save_samples(z, 'Convolve_samples_best.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a651b9b3-13b0-43e6-9b81-4b915c544497",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = tfd.MultivariateNormalDiag(loc=p, scale_diag=std)\n",
    "\n",
    "pred_model_best = p.sample(seed=rng_1)\n",
    "\n",
    "# Saving the samples of the predicted images and their difference from the original images\n",
    "save_samples(pred_model_best, 'MNDist_samples_best.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e747eaf8-7e3b-475a-846e-42989e26dd27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the differences between the predicted images of both models and their difference from the original images\n",
    "diff_inference(images, pred_model_1, pred_model_best, \"difference_pred_models_best.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eff81ab-9725-40fa-bd69-45ef283ae75a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing the AutoEncoder\n",
    "Autoencoder = AutoencoderKLModule(\n",
    "    ch_mult=(1, 2, 4, 8, 16),\n",
    "    num_res_blocks=2,\n",
    "    double_z=True,\n",
    "    z_channels=1,\n",
    "    resolution=latent_dim,\n",
    "    in_channels=1,\n",
    "    out_ch=1,\n",
    "    ch=1,\n",
    "    embed_dim=1,\n",
    "    act_fn=act_fn,\n",
    ")\n",
    "\n",
    "params = Autoencoder.init(rng, x=batch_autoenc, seed=rng_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0a9b2d3-91c6-4363-9fdc-3f399404a495",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_samples(z, batch, name):\n",
    "    # Plotting 16 images of the estimated shape of galaxies\n",
    "    num_rows, num_cols = 3, 4\n",
    "\n",
    "    fig, axes = plt.subplots(num_rows, num_cols, figsize=(10, 8))\n",
    "\n",
    "    for ax, z_img in zip(axes.flatten(), z):\n",
    "        ax.imshow(tf.math.reduce_mean(z_img, axis=-1))\n",
    "        # ax.imshow(z_img.mean(axis=-1))\n",
    "        ax.axis(\"off\")\n",
    "\n",
    "    # Add a title to the figure\n",
    "    fig.suptitle(\"Samples of predicted galaxies\", fontsize=16)\n",
    "\n",
    "    # Adjust the layout of the subplots\n",
    "    fig.tight_layout()\n",
    "\n",
    "    plt.savefig(name)\n",
    "    plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f0515c5-ccc5-458b-b9de-989da63a5669",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting over an example of data\n",
    "# Generating a random key for JAX\n",
    "rng, rng_2 = jax.random.PRNGKey(0), jax.random.PRNGKey(1)\n",
    "\n",
    "rng, rng_1 = jax.random.split(rng)\n",
    "# X estimated distribution\n",
    "q = Autoencoder.apply(params, x=galaxies_data, seed=rng_1)\n",
    "\n",
    "z = q\n",
    "\n",
    "# Saving the samples of the predicted images and their difference from the original images\n",
    "save_samples(z, galaxies_data, 'Autoencoder_FR_samples.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c7e349c-0e52-432b-88fc-c7b1d44b6e7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_fn(params, rng_key, batch, reg_term):  # state, rng_key, batch):\n",
    "    \"\"\"Function to define the loss function\"\"\"\n",
    "\n",
    "    x = batch[\"image\"]\n",
    "    kpsf_real = batch[\"kpsf_real\"]\n",
    "    kpsf_imag = batch[\"kpsf_imag\"]\n",
    "    kpsf = kpsf_real + 1j*kpsf_imag\n",
    "    # std = 0.005 * np.ones(x.shape[0], dtype=np.float32).reshape((-1, 1, 1, 1))\n",
    "    std = batch[\"noise_std\"].reshape((-1, 1, 1, 1))\n",
    "\n",
    "    # Autoencode an example\n",
    "    q = Autoencoder.apply(params, x=x, seed=rng_key)\n",
    "\n",
    "    p = jax.vmap(convolve_kpsf)(q[..., 0], kpsf[..., 0])\n",
    "\n",
    "    p = jnp.expand_dims(p, axis=-1)\n",
    "    \n",
    "    p = tfd.MultivariateNormalDiag(loc=p, scale_diag=std)\n",
    "\n",
    "    # KL divergence between the prior distribution and p\n",
    "    kl = tfd.kl_divergence(p, tfd.MultivariateNormalDiag(jnp.zeros((1, 128, 128, 1))))\n",
    "\n",
    "    # Compute log-likelihood\n",
    "    log_likelihood = p.log_prob(x)\n",
    "\n",
    "    # Calculating the ELBO value\n",
    "    elbo = (\n",
    "        log_likelihood - reg_term * kl\n",
    "    )  # Here we apply a regularization factor on the KL term\n",
    "\n",
    "    loss = -jnp.mean(elbo)\n",
    "    return loss, -jnp.mean(log_likelihood)\n",
    "\n",
    "# Veryfing that the 'value_and_grad' works fine\n",
    "\n",
    "kl_reg_w = 1e-3\n",
    "# (loss, log_likelihood), grads = jax.value_and_grad(loss_fn, has_aux=True)(params, rng, batch_im, kl_reg_w)\n",
    "(loss, log_likelihood), grads = jax.value_and_grad(loss_fn, has_aux=True)(params, rng, batch_im, kl_reg_w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2d6142e-02ce-462c-8600-7acc5e0a115a",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a03bebcd-4418-411d-85de-5f138f4e8c1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96ee4222-582a-4059-a132-0518534f04b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "grads;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db71d42f-9c6f-4f5e-9f32-26aa947dd6a0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
