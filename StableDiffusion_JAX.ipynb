{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# import torch.nn as nn\n",
    "\n",
    "\n",
    "# def Normalize(in_channels, num_groups=32):\n",
    "#     return torch.nn.GroupNorm(num_groups=num_groups, num_channels=in_channels, eps=1e-6, affine=True)\n",
    "\n",
    "# def nonlinearity(x):\n",
    "#     # swish\n",
    "#     return x*torch.sigmoid(x)\n",
    "\n",
    "# # def make_attn(in_channels, attn_type=\"vanilla\", attn_kwargs=None):\n",
    "# #     assert attn_type in [\"vanilla\", \"vanilla-xformers\", \"memory-efficient-cross-attn\", \"linear\", \"none\"], f'attn_type {attn_type} unknown'\n",
    "# #     if XFORMERS_IS_AVAILBLE and attn_type == \"vanilla\":\n",
    "# #         attn_type = \"vanilla-xformers\"\n",
    "# #     print(f\"making attention of type '{attn_type}' with {in_channels} in_channels\")\n",
    "# #     if attn_type == \"vanilla\":\n",
    "# #         assert attn_kwargs is None\n",
    "# #         return AttnBlock(in_channels)\n",
    "# #     elif attn_type == \"vanilla-xformers\":\n",
    "# #         print(f\"building MemoryEfficientAttnBlock with {in_channels} in_channels...\")\n",
    "# #         return MemoryEfficientAttnBlock(in_channels)\n",
    "# #     elif type == \"memory-efficient-cross-attn\":\n",
    "# #         attn_kwargs[\"query_dim\"] = in_channels\n",
    "# #         return MemoryEfficientCrossAttentionWrapper(**attn_kwargs)\n",
    "# #     elif attn_type == \"none\":\n",
    "# #         return nn.Identity(in_channels)\n",
    "# #     else:\n",
    "# #         raise NotImplementedError()\n",
    "    \n",
    "# class Upsample(nn.Module):\n",
    "#     def __init__(self, in_channels, with_conv):\n",
    "#         super().__init__()\n",
    "#         self.with_conv = with_conv\n",
    "#         if self.with_conv:\n",
    "#             self.conv = torch.nn.Conv2d(in_channels,\n",
    "#                                         in_channels,\n",
    "#                                         kernel_size=3,\n",
    "#                                         stride=1,\n",
    "#                                         padding=1)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         x = torch.nn.functional.interpolate(x, scale_factor=2.0, mode=\"nearest\")\n",
    "#         if self.with_conv:\n",
    "#             x = self.conv(x)\n",
    "#         return x\n",
    "\n",
    "    \n",
    "# class Downsample(nn.Module):\n",
    "#     def __init__(self, in_channels, with_conv):\n",
    "#         super().__init__()\n",
    "#         self.with_conv = with_conv\n",
    "#         if self.with_conv:\n",
    "#             # no asymmetric padding in torch conv, must do it ourselves\n",
    "#             self.conv = torch.nn.Conv2d(in_channels,\n",
    "#                                         in_channels,\n",
    "#                                         kernel_size=3,\n",
    "#                                         stride=2,\n",
    "#                                         padding=0)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         if self.with_conv:\n",
    "#             pad = (0,1,0,1)\n",
    "#             x = torch.nn.functional.pad(x, pad, mode=\"constant\", value=0)\n",
    "#             x = self.conv(x)\n",
    "#         else:\n",
    "#             x = torch.nn.functional.avg_pool2d(x, kernel_size=2, stride=2)\n",
    "#         return x\n",
    "\n",
    "# class ResnetBlock(nn.Module):\n",
    "#     def __init__(self, *, in_channels, out_channels=None, conv_shortcut=False,\n",
    "#                  dropout, temb_channels=512):\n",
    "#         super().__init__()\n",
    "#         self.in_channels = in_channels\n",
    "#         out_channels = in_channels if out_channels is None else out_channels\n",
    "#         self.out_channels = out_channels\n",
    "#         self.use_conv_shortcut = conv_shortcut\n",
    "\n",
    "#         self.norm1 = Normalize(in_channels)\n",
    "#         self.conv1 = torch.nn.Conv2d(in_channels,\n",
    "#                                      out_channels,\n",
    "#                                      kernel_size=3,\n",
    "#                                      stride=1,\n",
    "#                                      padding=1)\n",
    "#         if temb_channels > 0:\n",
    "#             self.temb_proj = torch.nn.Linear(temb_channels,\n",
    "#                                              out_channels)\n",
    "#         self.norm2 = Normalize(out_channels)\n",
    "#         self.dropout = torch.nn.Dropout(dropout)\n",
    "#         self.conv2 = torch.nn.Conv2d(out_channels,\n",
    "#                                      out_channels,\n",
    "#                                      kernel_size=3,\n",
    "#                                      stride=1,\n",
    "#                                      padding=1)\n",
    "#         if self.in_channels != self.out_channels:\n",
    "#             if self.use_conv_shortcut:\n",
    "#                 self.conv_shortcut = torch.nn.Conv2d(in_channels,\n",
    "#                                                      out_channels,\n",
    "#                                                      kernel_size=3,\n",
    "#                                                      stride=1,\n",
    "#                                                      padding=1)\n",
    "#             else:\n",
    "#                 self.nin_shortcut = torch.nn.Conv2d(in_channels,\n",
    "#                                                     out_channels,\n",
    "#                                                     kernel_size=1,\n",
    "#                                                     stride=1,\n",
    "#                                                     padding=0)\n",
    "\n",
    "#     def forward(self, x, temb):\n",
    "#         h = x\n",
    "#         h = self.norm1(h)\n",
    "#         h = nonlinearity(h)\n",
    "#         h = self.conv1(h)\n",
    "\n",
    "#         if temb is not None:\n",
    "#             h = h + self.temb_proj(nonlinearity(temb))[:,:,None,None]\n",
    "\n",
    "#         h = self.norm2(h)\n",
    "#         h = nonlinearity(h)\n",
    "#         h = self.dropout(h)\n",
    "#         h = self.conv2(h)\n",
    "\n",
    "#         if self.in_channels != self.out_channels:\n",
    "#             if self.use_conv_shortcut:\n",
    "#                 x = self.conv_shortcut(x)\n",
    "#             else:\n",
    "#                 x = self.nin_shortcut(x)\n",
    "\n",
    "#         return x+h\n",
    "\n",
    "\n",
    "# class Encoder(nn.Module):\n",
    "#     def __init__(self, *, ch, out_ch, ch_mult=(1,2,4,8), num_res_blocks,\n",
    "#                  attn_resolutions, dropout=0.0, resamp_with_conv=True, in_channels,\n",
    "#                  resolution, z_channels, double_z=True, use_linear_attn=False, attn_type=\"vanilla\",\n",
    "#                  **ignore_kwargs):\n",
    "#         super().__init__()\n",
    "#         if use_linear_attn: attn_type = \"linear\"\n",
    "#         self.ch = ch\n",
    "#         self.temb_ch = 0\n",
    "#         self.num_resolutions = len(ch_mult)\n",
    "#         self.num_res_blocks = num_res_blocks\n",
    "#         self.resolution = resolution\n",
    "#         self.in_channels = in_channels\n",
    "\n",
    "#         # downsampling\n",
    "#         self.conv_in = torch.nn.Conv2d(in_channels,\n",
    "#                                        self.ch,\n",
    "#                                        kernel_size=3,\n",
    "#                                        stride=1,\n",
    "#                                        padding=1)\n",
    "\n",
    "#         curr_res = resolution\n",
    "#         in_ch_mult = (1,)+tuple(ch_mult)\n",
    "#         self.in_ch_mult = in_ch_mult\n",
    "#         self.down = nn.ModuleList()\n",
    "#         for i_level in range(self.num_resolutions):\n",
    "#             block = nn.ModuleList()\n",
    "#             attn = nn.ModuleList()\n",
    "#             block_in = ch*in_ch_mult[i_level]\n",
    "#             block_out = ch*ch_mult[i_level]\n",
    "#             for i_block in range(self.num_res_blocks):\n",
    "#                 block.append(ResnetBlock(in_channels=block_in,\n",
    "#                                          out_channels=block_out,\n",
    "#                                          temb_channels=self.temb_ch,\n",
    "#                                          dropout=dropout))\n",
    "#                 block_in = block_out\n",
    "#                 if curr_res in attn_resolutions:\n",
    "#                     attn.append(make_attn(block_in, attn_type=attn_type))\n",
    "#             down = nn.Module()\n",
    "#             down.block = block\n",
    "#             down.attn = attn\n",
    "#             if i_level != self.num_resolutions-1:\n",
    "#                 down.downsample = Downsample(block_in, resamp_with_conv)\n",
    "#                 curr_res = curr_res // 2\n",
    "#             self.down.append(down)\n",
    "\n",
    "#         # middle\n",
    "#         self.mid = nn.Module()\n",
    "#         self.mid.block_1 = ResnetBlock(in_channels=block_in,\n",
    "#                                        out_channels=block_in,\n",
    "#                                        temb_channels=self.temb_ch,\n",
    "#                                        dropout=dropout)\n",
    "#         self.mid.attn_1 = make_attn(block_in, attn_type=attn_type)\n",
    "#         self.mid.block_2 = ResnetBlock(in_channels=block_in,\n",
    "#                                        out_channels=block_in,\n",
    "#                                        temb_channels=self.temb_ch,\n",
    "#                                        dropout=dropout)\n",
    "\n",
    "#         # end\n",
    "#         self.norm_out = Normalize(block_in)\n",
    "#         self.conv_out = torch.nn.Conv2d(block_in,\n",
    "#                                         2*z_channels if double_z else z_channels,\n",
    "#                                         kernel_size=3,\n",
    "#                                         stride=1,\n",
    "#                                         padding=1)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         # timestep embedding\n",
    "#         temb = None\n",
    "\n",
    "#         # downsampling\n",
    "#         hs = [self.conv_in(x)]\n",
    "#         for i_level in range(self.num_resolutions):\n",
    "#             for i_block in range(self.num_res_blocks):\n",
    "#                 h = self.down[i_level].block[i_block](hs[-1], temb)\n",
    "#                 if len(self.down[i_level].attn) > 0:\n",
    "#                     h = self.down[i_level].attn[i_block](h)\n",
    "#                 hs.append(h)\n",
    "#             if i_level != self.num_resolutions-1:\n",
    "#                 hs.append(self.down[i_level].downsample(hs[-1]))\n",
    "\n",
    "#         # middle\n",
    "#         h = hs[-1]\n",
    "#         h = self.mid.block_1(h, temb)\n",
    "#         h = self.mid.attn_1(h)\n",
    "#         h = self.mid.block_2(h, temb)\n",
    "\n",
    "#         # end\n",
    "#         h = self.norm_out(h)\n",
    "#         h = nonlinearity(h)\n",
    "#         h = self.conv_out(h)\n",
    "#         return h\n",
    "\n",
    "\n",
    "# class Decoder(nn.Module):\n",
    "#     def __init__(self, *, ch, out_ch, ch_mult=(1,2,4,8), num_res_blocks,\n",
    "#                  attn_resolutions, dropout=0.0, resamp_with_conv=True, in_channels,\n",
    "#                  resolution, z_channels, give_pre_end=False, tanh_out=False, use_linear_attn=False,\n",
    "#                  attn_type=\"vanilla\", **ignorekwargs):\n",
    "#         super().__init__()\n",
    "#         if use_linear_attn: attn_type = \"linear\"\n",
    "#         self.ch = ch\n",
    "#         self.temb_ch = 0\n",
    "#         self.num_resolutions = len(ch_mult)\n",
    "#         self.num_res_blocks = num_res_blocks\n",
    "#         self.resolution = resolution\n",
    "#         self.in_channels = in_channels\n",
    "#         self.give_pre_end = give_pre_end\n",
    "#         self.tanh_out = tanh_out\n",
    "\n",
    "#         # compute in_ch_mult, block_in and curr_res at lowest res\n",
    "#         in_ch_mult = (1,)+tuple(ch_mult)\n",
    "#         block_in = ch*ch_mult[self.num_resolutions-1]\n",
    "#         curr_res = resolution // 2**(self.num_resolutions-1)\n",
    "#         self.z_shape = (1,z_channels,curr_res,curr_res)\n",
    "#         print(\"Working with z of shape {} = {} dimensions.\".format(\n",
    "#             self.z_shape, np.prod(self.z_shape)))\n",
    "\n",
    "#         # z to block_in\n",
    "#         self.conv_in = torch.nn.Conv2d(z_channels,\n",
    "#                                        block_in,\n",
    "#                                        kernel_size=3,\n",
    "#                                        stride=1,\n",
    "#                                        padding=1)\n",
    "\n",
    "#         # middle\n",
    "#         self.mid = nn.Module()\n",
    "#         self.mid.block_1 = ResnetBlock(in_channels=block_in,\n",
    "#                                        out_channels=block_in,\n",
    "#                                        temb_channels=self.temb_ch,\n",
    "#                                        dropout=dropout)\n",
    "#         self.mid.attn_1 = make_attn(block_in, attn_type=attn_type)\n",
    "#         self.mid.block_2 = ResnetBlock(in_channels=block_in,\n",
    "#                                        out_channels=block_in,\n",
    "#                                        temb_channels=self.temb_ch,\n",
    "#                                        dropout=dropout)\n",
    "\n",
    "#         # upsampling\n",
    "#         self.up = nn.ModuleList()\n",
    "#         for i_level in reversed(range(self.num_resolutions)):\n",
    "#             block = nn.ModuleList()\n",
    "#             attn = nn.ModuleList()\n",
    "#             block_out = ch*ch_mult[i_level]\n",
    "#             for i_block in range(self.num_res_blocks+1):\n",
    "#                 block.append(ResnetBlock(in_channels=block_in,\n",
    "#                                          out_channels=block_out,\n",
    "#                                          temb_channels=self.temb_ch,\n",
    "#                                          dropout=dropout))\n",
    "#                 block_in = block_out\n",
    "#                 if curr_res in attn_resolutions:\n",
    "#                     attn.append(make_attn(block_in, attn_type=attn_type))\n",
    "#             up = nn.Module()\n",
    "#             up.block = block\n",
    "#             up.attn = attn\n",
    "#             if i_level != 0:\n",
    "#                 up.upsample = Upsample(block_in, resamp_with_conv)\n",
    "#                 curr_res = curr_res * 2\n",
    "#             self.up.insert(0, up) # prepend to get consistent order\n",
    "\n",
    "#         # end\n",
    "#         self.norm_out = Normalize(block_in)\n",
    "#         self.conv_out = torch.nn.Conv2d(block_in,\n",
    "#                                         out_ch,\n",
    "#                                         kernel_size=3,\n",
    "#                                         stride=1,\n",
    "#                                         padding=1)\n",
    "\n",
    "#     def forward(self, z):\n",
    "#         #assert z.shape[1:] == self.z_shape[1:]\n",
    "#         self.last_z_shape = z.shape\n",
    "\n",
    "#         # timestep embedding\n",
    "#         temb = None\n",
    "\n",
    "#         # z to block_in\n",
    "#         h = self.conv_in(z)\n",
    "\n",
    "#         # middle\n",
    "#         h = self.mid.block_1(h, temb)\n",
    "#         h = self.mid.attn_1(h)\n",
    "#         h = self.mid.block_2(h, temb)\n",
    "\n",
    "#         # upsampling\n",
    "#         for i_level in reversed(range(self.num_resolutions)):\n",
    "#             for i_block in range(self.num_res_blocks+1):\n",
    "#                 h = self.up[i_level].block[i_block](h, temb)\n",
    "#                 if len(self.up[i_level].attn) > 0:\n",
    "#                     h = self.up[i_level].attn[i_block](h)\n",
    "#             if i_level != 0:\n",
    "#                 h = self.up[i_level].upsample(h)\n",
    "\n",
    "#         # end\n",
    "#         if self.give_pre_end:\n",
    "#             return h\n",
    "\n",
    "#         h = self.norm_out(h)\n",
    "#         h = nonlinearity(h)\n",
    "#         h = self.conv_out(h)\n",
    "#         if self.tanh_out:\n",
    "#             h = torch.tanh(h)\n",
    "#         return h\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from flax import linen as nn\n",
    "\n",
    "def Normalize(num_groups=10):\n",
    "    return nn.GroupNorm(num_groups=num_groups, epsilon=1e-6, use_scale=True)\n",
    "\n",
    "class Downsample(nn.Module):\n",
    "    in_channels: int\n",
    "    \n",
    "    def setup(self):\n",
    "        self.conv = nn.Conv(\n",
    "            self.in_channels,\n",
    "            kernel_size=(3, 3),\n",
    "            strides=(2, 2),\n",
    "            padding=((0, 1), (0, 1)),\n",
    "            )\n",
    "\n",
    "    def __call__(self, x):\n",
    "        pad = ((0, 0), (0, 1), (0, 0), (0, 1))\n",
    "        x = jnp.pad(x, pad, mode=\"constant\", constant_values=0)\n",
    "        x = self.conv(x)\n",
    "        return x\n",
    "\n",
    "class ResnetBlock(nn.Module):\n",
    "    in_channels: int\n",
    "    out_channels: int\n",
    "    \n",
    "    def setup(self):\n",
    "\n",
    "        self.norm1 = Normalize(num_groups=5)\n",
    "        self.conv1 = nn.Conv(\n",
    "            self.out_channels,\n",
    "            kernel_size=(3, 3),\n",
    "            strides=(1, 1),\n",
    "            padding=((1, 1), (1, 1)),\n",
    "        )\n",
    "        self.norm2 = Normalize(num_groups=5)\n",
    "        self.conv2 = nn.Conv(\n",
    "            self.out_channels,\n",
    "            kernel_size=(3, 3),\n",
    "            strides=(1, 1),\n",
    "            padding=((1, 1), (1, 1)),\n",
    "        )\n",
    "\n",
    "        self.nin_shortcut = nn.Conv(\n",
    "            self.out_channels,\n",
    "            kernel_size=(1, 1),\n",
    "            strides=(1, 1),\n",
    "            padding=((0, 0), (0, 0)),\n",
    "        )\n",
    "\n",
    "    def __call__(self, x):\n",
    "        h = x\n",
    "        h = self.norm1(h)\n",
    "        h = nn.swish(h)\n",
    "        h = self.conv1(h)\n",
    "        h = self.norm2(h)\n",
    "        h = nn.swish(h)\n",
    "        h = self.conv2(h)\n",
    "        x = self.nin_shortcut(x)\n",
    "        x_ = x+h \n",
    "        \n",
    "        return x + h\n",
    "    \n",
    "class DownsamplingBlock(nn.Module):\n",
    "    ch: int\n",
    "    ch_mult: tuple\n",
    "    num_res_blocks: int\n",
    "    resolution: int\n",
    "    block_idx: int\n",
    "    \n",
    "    def setup(self):\n",
    "        self.ch_mult_ = self.ch_mult \n",
    "        self.num_resolutions = len(self.ch_mult_)\n",
    "        in_ch_mult = (1, ) + tuple(self.ch_mult_)\n",
    "        block_in = self.ch * in_ch_mult[self.block_idx]\n",
    "        block_out = self.ch * self.ch_mult_[self.block_idx]\n",
    "\n",
    "        res_blocks = []\n",
    "        for _ in range(self.num_res_blocks):\n",
    "            res_blocks.append(ResnetBlock(block_in,\n",
    "                                          block_out,\n",
    "                                         ))\n",
    "        block_in = block_out\n",
    "        self.block = res_blocks\n",
    "\n",
    "        self.downsample = None\n",
    "        if self.block_idx != self.num_resolutions - 1:\n",
    "            self.downsample = Downsample(block_in)\n",
    "\n",
    "    def __call__(self, h):\n",
    "        for i, res_block in enumerate(self.block):\n",
    "            h = res_block(h)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            h = self.downsample(h)\n",
    "\n",
    "        return h    \n",
    "\n",
    "    \n",
    "class MidBlock(nn.Module):\n",
    "    in_channels : int\n",
    "    \n",
    "    def setup(self):\n",
    "        self.block_1 = ResnetBlock(\n",
    "            self.in_channels,\n",
    "            self.in_channels,\n",
    "        )\n",
    "        self.block_2 = ResnetBlock(\n",
    "            self.in_channels,\n",
    "            self.in_channels,\n",
    "        )\n",
    "        \n",
    "    def __call__(self, h):\n",
    "        h = self.block_1(h)\n",
    "        h = self.block_2(h)\n",
    "        \n",
    "        return h\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    ch: int\n",
    "    out_ch: int\n",
    "    ch_mult: tuple\n",
    "    num_res_blocks: int\n",
    "    in_channels: int\n",
    "    resolution: int\n",
    "    z_channels: int\n",
    "    double_z: bool\n",
    "\n",
    "\n",
    "    def setup(self):\n",
    "        \n",
    "        self.num_resolutions = len(self.ch_mult)\n",
    "        \n",
    "        # downsampling\n",
    "        self.conv_in = nn.Conv(\n",
    "            self.ch,\n",
    "            kernel_size=(3, 3),\n",
    "            strides=(1, 1),\n",
    "            padding=((1, 1), (1, 1)),\n",
    "        )\n",
    "        \n",
    "        curr_res = self.resolution\n",
    "        downsample_blocks = []\n",
    "        \n",
    "        for i_level in range(self.num_resolutions):\n",
    "            downsample_blocks.append(\n",
    "                DownsamplingBlock(ch=self.ch,\n",
    "                                  ch_mult=self.ch_mult,\n",
    "                                  num_res_blocks=self.num_res_blocks,\n",
    "                                  resolution=self.resolution,\n",
    "                                  block_idx=i_level,\n",
    "                                 ))\n",
    "            if i_level != self.num_resolutions - 1:\n",
    "                curr_res = curr_res // 2\n",
    "                        \n",
    "        self.down = downsample_blocks\n",
    "\n",
    "        # middle\n",
    "        mid_channels = self.ch * self.ch_mult[-1]\n",
    "        self.mid = MidBlock(mid_channels)\n",
    "        # end\n",
    "        self.norm_out = Normalize()\n",
    "        self.conv_out = nn.Conv(\n",
    "            self.z_channels * 2 if self.double_z else self.z_channels,\n",
    "            kernel_size=(3, 3),\n",
    "            strides=(1, 1),\n",
    "            padding=((1, 1), (1, 1)),\n",
    "        )\n",
    "\n",
    "    def __call__(self, x):\n",
    "\n",
    "        # downsampling\n",
    "        print(\"x :\", x.shape)\n",
    "        hs = self.conv_in(x)\n",
    "        print(\"Conv_in :\", hs.shape)\n",
    "        for block in self.down:\n",
    "            hs = block(hs)\n",
    "        print(\"Down :\", hs.shape)\n",
    "\n",
    "        # middle\n",
    "        hs = self.mid(hs)\n",
    "        print(\"Mid :\", hs.shape)\n",
    "        \n",
    "        # end\n",
    "        hs = self.norm_out(hs)\n",
    "        hs = nn.swish(hs)\n",
    "        hs = self.conv_out(hs)\n",
    "        print(\"Conv_out :\", hs.shape)\n",
    "        return hs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 32, 32, 5)\n",
      "\n",
      "\u001b[3m                               Downsample Summary                               \u001b[0m\n",
      "┏━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
      "┃\u001b[1m \u001b[0m\u001b[1mpath\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mmodule    \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1minputs           \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1moutputs         \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mparams           \u001b[0m\u001b[1m \u001b[0m┃\n",
      "┡━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
      "│      │ Downsample │ \u001b[2mfloat32\u001b[0m[1,64,64,… │ \u001b[2mfloat32\u001b[0m[1,32,32… │                   │\n",
      "├──────┼────────────┼───────────────────┼──────────────────┼───────────────────┤\n",
      "│ conv │ Conv       │ \u001b[2mfloat32\u001b[0m[1,65,64,… │ \u001b[2mfloat32\u001b[0m[1,32,32… │ bias: \u001b[2mfloat32\u001b[0m[5]  │\n",
      "│      │            │                   │                  │ kernel:           │\n",
      "│      │            │                   │                  │ \u001b[2mfloat32\u001b[0m[3,3,6,5]  │\n",
      "│      │            │                   │                  │                   │\n",
      "│      │            │                   │                  │ \u001b[1m275 \u001b[0m\u001b[1;2m(1.1 KB)\u001b[0m      │\n",
      "├──────┼────────────┼───────────────────┼──────────────────┼───────────────────┤\n",
      "│\u001b[1m \u001b[0m\u001b[1m    \u001b[0m\u001b[1m \u001b[0m│\u001b[1m \u001b[0m\u001b[1m          \u001b[0m\u001b[1m \u001b[0m│\u001b[1m \u001b[0m\u001b[1m                 \u001b[0m\u001b[1m \u001b[0m│\u001b[1m \u001b[0m\u001b[1m           Total\u001b[0m\u001b[1m \u001b[0m│\u001b[1m \u001b[0m\u001b[1m275 \u001b[0m\u001b[1;2m(1.1 KB)\u001b[0m\u001b[1m     \u001b[0m\u001b[1m \u001b[0m│\n",
      "└──────┴────────────┴───────────────────┴──────────────────┴───────────────────┘\n",
      "\u001b[1m                                                                                \u001b[0m\n",
      "\u001b[1m                         Total Parameters: 275 \u001b[0m\u001b[1;2m(1.1 KB)\u001b[0m\u001b[1m                         \u001b[0m\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "input_shape = (1, 64, 64, 5)  # (batch_size, height, width, channels)\n",
    "\n",
    "# Create an instance of Downsample\n",
    "downsample = Downsample(in_channels=5)\n",
    "\n",
    "# Generate random input\n",
    "rng = jax.random.PRNGKey(0)\n",
    "x = jax.random.normal(rng, input_shape)\n",
    "\n",
    "# Initialize the module and apply it to the input\n",
    "params = downsample.init(rng, x)\n",
    "output = downsample.apply(params, x)\n",
    "\n",
    "# Print the output shape\n",
    "print(output.shape)\n",
    "\n",
    "print(Downsample(in_channels=5).tabulate(rng,x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 32, 32, 10)\n",
      "\n",
      "\u001b[3m                           DownsamplingBlock Summary                            \u001b[0m\n",
      "┏━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━┓\n",
      "┃\u001b[1m \u001b[0m\u001b[1mpath         \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mmodule       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1minputs       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1moutputs      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mparams      \u001b[0m\u001b[1m \u001b[0m┃\n",
      "┡━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━┩\n",
      "│               │ Downsampling… │ \u001b[2mfloat32\u001b[0m[1,64… │ \u001b[2mfloat32\u001b[0m[1,32… │              │\n",
      "├───────────────┼───────────────┼───────────────┼───────────────┼──────────────┤\n",
      "│ block_0       │ ResnetBlock   │ \u001b[2mfloat32\u001b[0m[1,64… │ \u001b[2mfloat32\u001b[0m[1,64… │              │\n",
      "├───────────────┼───────────────┼───────────────┼───────────────┼──────────────┤\n",
      "│ block_0/norm1 │ GroupNorm     │ \u001b[2mfloat32\u001b[0m[1,64… │ \u001b[2mfloat32\u001b[0m[1,64… │ bias:        │\n",
      "│               │               │               │               │ \u001b[2mfloat32\u001b[0m[5]   │\n",
      "│               │               │               │               │ scale:       │\n",
      "│               │               │               │               │ \u001b[2mfloat32\u001b[0m[5]   │\n",
      "│               │               │               │               │              │\n",
      "│               │               │               │               │ \u001b[1m10 \u001b[0m\u001b[1;2m(40 B)\u001b[0m    │\n",
      "├───────────────┼───────────────┼───────────────┼───────────────┼──────────────┤\n",
      "│ block_0/conv1 │ Conv          │ \u001b[2mfloat32\u001b[0m[1,64… │ \u001b[2mfloat32\u001b[0m[1,64… │ bias:        │\n",
      "│               │               │               │               │ \u001b[2mfloat32\u001b[0m[10]  │\n",
      "│               │               │               │               │ kernel:      │\n",
      "│               │               │               │               │ \u001b[2mfloat32\u001b[0m[3,3… │\n",
      "│               │               │               │               │              │\n",
      "│               │               │               │               │ \u001b[1m460 \u001b[0m\u001b[1;2m(1.8 KB)\u001b[0m │\n",
      "├───────────────┼───────────────┼───────────────┼───────────────┼──────────────┤\n",
      "│ block_0/norm2 │ GroupNorm     │ \u001b[2mfloat32\u001b[0m[1,64… │ \u001b[2mfloat32\u001b[0m[1,64… │ bias:        │\n",
      "│               │               │               │               │ \u001b[2mfloat32\u001b[0m[10]  │\n",
      "│               │               │               │               │ scale:       │\n",
      "│               │               │               │               │ \u001b[2mfloat32\u001b[0m[10]  │\n",
      "│               │               │               │               │              │\n",
      "│               │               │               │               │ \u001b[1m20 \u001b[0m\u001b[1;2m(80 B)\u001b[0m    │\n",
      "├───────────────┼───────────────┼───────────────┼───────────────┼──────────────┤\n",
      "│ block_0/conv2 │ Conv          │ \u001b[2mfloat32\u001b[0m[1,64… │ \u001b[2mfloat32\u001b[0m[1,64… │ bias:        │\n",
      "│               │               │               │               │ \u001b[2mfloat32\u001b[0m[10]  │\n",
      "│               │               │               │               │ kernel:      │\n",
      "│               │               │               │               │ \u001b[2mfloat32\u001b[0m[3,3… │\n",
      "│               │               │               │               │              │\n",
      "│               │               │               │               │ \u001b[1m910 \u001b[0m\u001b[1;2m(3.6 KB)\u001b[0m │\n",
      "├───────────────┼───────────────┼───────────────┼───────────────┼──────────────┤\n",
      "│ block_0/nin_… │ Conv          │ \u001b[2mfloat32\u001b[0m[1,64… │ \u001b[2mfloat32\u001b[0m[1,64… │ bias:        │\n",
      "│               │               │               │               │ \u001b[2mfloat32\u001b[0m[10]  │\n",
      "│               │               │               │               │ kernel:      │\n",
      "│               │               │               │               │ \u001b[2mfloat32\u001b[0m[1,1… │\n",
      "│               │               │               │               │              │\n",
      "│               │               │               │               │ \u001b[1m60 \u001b[0m\u001b[1;2m(240 B)\u001b[0m   │\n",
      "├───────────────┼───────────────┼───────────────┼───────────────┼──────────────┤\n",
      "│ block_1       │ ResnetBlock   │ \u001b[2mfloat32\u001b[0m[1,64… │ \u001b[2mfloat32\u001b[0m[1,64… │              │\n",
      "├───────────────┼───────────────┼───────────────┼───────────────┼──────────────┤\n",
      "│ block_1/norm1 │ GroupNorm     │ \u001b[2mfloat32\u001b[0m[1,64… │ \u001b[2mfloat32\u001b[0m[1,64… │ bias:        │\n",
      "│               │               │               │               │ \u001b[2mfloat32\u001b[0m[10]  │\n",
      "│               │               │               │               │ scale:       │\n",
      "│               │               │               │               │ \u001b[2mfloat32\u001b[0m[10]  │\n",
      "│               │               │               │               │              │\n",
      "│               │               │               │               │ \u001b[1m20 \u001b[0m\u001b[1;2m(80 B)\u001b[0m    │\n",
      "├───────────────┼───────────────┼───────────────┼───────────────┼──────────────┤\n",
      "│ block_1/conv1 │ Conv          │ \u001b[2mfloat32\u001b[0m[1,64… │ \u001b[2mfloat32\u001b[0m[1,64… │ bias:        │\n",
      "│               │               │               │               │ \u001b[2mfloat32\u001b[0m[10]  │\n",
      "│               │               │               │               │ kernel:      │\n",
      "│               │               │               │               │ \u001b[2mfloat32\u001b[0m[3,3… │\n",
      "│               │               │               │               │              │\n",
      "│               │               │               │               │ \u001b[1m910 \u001b[0m\u001b[1;2m(3.6 KB)\u001b[0m │\n",
      "├───────────────┼───────────────┼───────────────┼───────────────┼──────────────┤\n",
      "│ block_1/norm2 │ GroupNorm     │ \u001b[2mfloat32\u001b[0m[1,64… │ \u001b[2mfloat32\u001b[0m[1,64… │ bias:        │\n",
      "│               │               │               │               │ \u001b[2mfloat32\u001b[0m[10]  │\n",
      "│               │               │               │               │ scale:       │\n",
      "│               │               │               │               │ \u001b[2mfloat32\u001b[0m[10]  │\n",
      "│               │               │               │               │              │\n",
      "│               │               │               │               │ \u001b[1m20 \u001b[0m\u001b[1;2m(80 B)\u001b[0m    │\n",
      "├───────────────┼───────────────┼───────────────┼───────────────┼──────────────┤\n",
      "│ block_1/conv2 │ Conv          │ \u001b[2mfloat32\u001b[0m[1,64… │ \u001b[2mfloat32\u001b[0m[1,64… │ bias:        │\n",
      "│               │               │               │               │ \u001b[2mfloat32\u001b[0m[10]  │\n",
      "│               │               │               │               │ kernel:      │\n",
      "│               │               │               │               │ \u001b[2mfloat32\u001b[0m[3,3… │\n",
      "│               │               │               │               │              │\n",
      "│               │               │               │               │ \u001b[1m910 \u001b[0m\u001b[1;2m(3.6 KB)\u001b[0m │\n",
      "├───────────────┼───────────────┼───────────────┼───────────────┼──────────────┤\n",
      "│ block_1/nin_… │ Conv          │ \u001b[2mfloat32\u001b[0m[1,64… │ \u001b[2mfloat32\u001b[0m[1,64… │ bias:        │\n",
      "│               │               │               │               │ \u001b[2mfloat32\u001b[0m[10]  │\n",
      "│               │               │               │               │ kernel:      │\n",
      "│               │               │               │               │ \u001b[2mfloat32\u001b[0m[1,1… │\n",
      "│               │               │               │               │              │\n",
      "│               │               │               │               │ \u001b[1m110 \u001b[0m\u001b[1;2m(440 B)\u001b[0m  │\n",
      "├───────────────┼───────────────┼───────────────┼───────────────┼──────────────┤\n",
      "│ downsample    │ Downsample    │ \u001b[2mfloat32\u001b[0m[1,64… │ \u001b[2mfloat32\u001b[0m[1,32… │              │\n",
      "├───────────────┼───────────────┼───────────────┼───────────────┼──────────────┤\n",
      "│ downsample/c… │ Conv          │ \u001b[2mfloat32\u001b[0m[1,65… │ \u001b[2mfloat32\u001b[0m[1,32… │ bias:        │\n",
      "│               │               │               │               │ \u001b[2mfloat32\u001b[0m[10]  │\n",
      "│               │               │               │               │ kernel:      │\n",
      "│               │               │               │               │ \u001b[2mfloat32\u001b[0m[3,3… │\n",
      "│               │               │               │               │              │\n",
      "│               │               │               │               │ \u001b[1m1,000 \u001b[0m\u001b[1;2m(4.0 \u001b[0m  │\n",
      "│               │               │               │               │ \u001b[1;2mKB)\u001b[0m          │\n",
      "├───────────────┼───────────────┼───────────────┼───────────────┼──────────────┤\n",
      "│\u001b[1m \u001b[0m\u001b[1m             \u001b[0m\u001b[1m \u001b[0m│\u001b[1m \u001b[0m\u001b[1m             \u001b[0m\u001b[1m \u001b[0m│\u001b[1m \u001b[0m\u001b[1m             \u001b[0m\u001b[1m \u001b[0m│\u001b[1m \u001b[0m\u001b[1m        Total\u001b[0m\u001b[1m \u001b[0m│\u001b[1m \u001b[0m\u001b[1m4,430 \u001b[0m\u001b[1;2m(17.7 \u001b[0m\u001b[1m \u001b[0m│\n",
      "│\u001b[1m               \u001b[0m│\u001b[1m               \u001b[0m│\u001b[1m               \u001b[0m│\u001b[1m               \u001b[0m│\u001b[1m \u001b[0m\u001b[1;2mKB)\u001b[0m\u001b[1m         \u001b[0m\u001b[1m \u001b[0m│\n",
      "└───────────────┴───────────────┴───────────────┴───────────────┴──────────────┘\n",
      "\u001b[1m                                                                                \u001b[0m\n",
      "\u001b[1m                       Total Parameters: 4,430 \u001b[0m\u001b[1;2m(17.7 KB)\u001b[0m\u001b[1m                        \u001b[0m\n",
      "\n",
      "\n",
      "+------------------------------------+----------------+------+----------+--------+\n",
      "| Name                               | Shape          | Size | Mean     | Std    |\n",
      "+------------------------------------+----------------+------+----------+--------+\n",
      "| params/block_0/conv1/bias          | (10,)          | 10   | 0.0      | 0.0    |\n",
      "| params/block_0/conv1/kernel        | (3, 3, 5, 10)  | 450  | 0.00705  | 0.15   |\n",
      "| params/block_0/conv2/bias          | (10,)          | 10   | 0.0      | 0.0    |\n",
      "| params/block_0/conv2/kernel        | (3, 3, 10, 10) | 900  | 0.00313  | 0.105  |\n",
      "| params/block_0/nin_shortcut/bias   | (10,)          | 10   | 0.0      | 0.0    |\n",
      "| params/block_0/nin_shortcut/kernel | (1, 1, 5, 10)  | 50   | -0.0674  | 0.425  |\n",
      "| params/block_0/norm1/bias          | (5,)           | 5    | 0.0      | 0.0    |\n",
      "| params/block_0/norm1/scale         | (5,)           | 5    | 1.0      | 0.0    |\n",
      "| params/block_0/norm2/bias          | (10,)          | 10   | 0.0      | 0.0    |\n",
      "| params/block_0/norm2/scale         | (10,)          | 10   | 1.0      | 0.0    |\n",
      "| params/block_1/conv1/bias          | (10,)          | 10   | 0.0      | 0.0    |\n",
      "| params/block_1/conv1/kernel        | (3, 3, 10, 10) | 900  | -0.00276 | 0.106  |\n",
      "| params/block_1/conv2/bias          | (10,)          | 10   | 0.0      | 0.0    |\n",
      "| params/block_1/conv2/kernel        | (3, 3, 10, 10) | 900  | 0.0034   | 0.108  |\n",
      "| params/block_1/nin_shortcut/bias   | (10,)          | 10   | 0.0      | 0.0    |\n",
      "| params/block_1/nin_shortcut/kernel | (1, 1, 10, 10) | 100  | 0.0222   | 0.287  |\n",
      "| params/block_1/norm1/bias          | (10,)          | 10   | 0.0      | 0.0    |\n",
      "| params/block_1/norm1/scale         | (10,)          | 10   | 1.0      | 0.0    |\n",
      "| params/block_1/norm2/bias          | (10,)          | 10   | 0.0      | 0.0    |\n",
      "| params/block_1/norm2/scale         | (10,)          | 10   | 1.0      | 0.0    |\n",
      "| params/downsample/conv/bias        | (10,)          | 10   | 0.0      | 0.0    |\n",
      "| params/downsample/conv/kernel      | (3, 3, 11, 10) | 990  | 0.00174  | 0.0993 |\n",
      "+------------------------------------+----------------+------+----------+--------+\n",
      "Total: 4,430\n"
     ]
    }
   ],
   "source": [
    "from clu import parameter_overview\n",
    "\n",
    "# Generate random input tensors\n",
    "x = jnp.zeros((1, 64, 64, 5))\n",
    "rng = jax.random.PRNGKey(0)\n",
    "\n",
    "# Initialize DownsamplingBlock\n",
    "down_block = DownsamplingBlock(\n",
    "    ch=5,\n",
    "    ch_mult=(1,2,4),\n",
    "    num_res_blocks=2,\n",
    "    resolution=64,\n",
    "    block_idx=1,\n",
    ")\n",
    "\n",
    "params = down_block.init(rng, x)\n",
    "# Apply DownsamplingBlock using the apply method\n",
    "output = down_block.apply({'params': params['params']}, x)\n",
    "print(output.shape)\n",
    "\n",
    "print(down_block.tabulate(rng, x))\n",
    "\n",
    "print(parameter_overview.get_parameter_overview(params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 64, 64, 5)\n",
      "\n",
      "\u001b[3m                              ResnetBlock Summary                               \u001b[0m\n",
      "┏━━━━━━━━━━━━━━┳━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
      "┃\u001b[1m \u001b[0m\u001b[1mpath        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mmodule     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1minputs        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1moutputs       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mparams       \u001b[0m\u001b[1m \u001b[0m┃\n",
      "┡━━━━━━━━━━━━━━╇━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
      "│              │ ResnetBlock │ \u001b[2mfloat32\u001b[0m[1,64,… │ \u001b[2mfloat32\u001b[0m[1,64,… │               │\n",
      "├──────────────┼─────────────┼────────────────┼────────────────┼───────────────┤\n",
      "│ norm1        │ GroupNorm   │ \u001b[2mfloat32\u001b[0m[1,64,… │ \u001b[2mfloat32\u001b[0m[1,64,… │ bias:         │\n",
      "│              │             │                │                │ \u001b[2mfloat32\u001b[0m[5]    │\n",
      "│              │             │                │                │ scale:        │\n",
      "│              │             │                │                │ \u001b[2mfloat32\u001b[0m[5]    │\n",
      "│              │             │                │                │               │\n",
      "│              │             │                │                │ \u001b[1m10 \u001b[0m\u001b[1;2m(40 B)\u001b[0m     │\n",
      "├──────────────┼─────────────┼────────────────┼────────────────┼───────────────┤\n",
      "│ conv1        │ Conv        │ \u001b[2mfloat32\u001b[0m[1,64,… │ \u001b[2mfloat32\u001b[0m[1,64,… │ bias:         │\n",
      "│              │             │                │                │ \u001b[2mfloat32\u001b[0m[5]    │\n",
      "│              │             │                │                │ kernel:       │\n",
      "│              │             │                │                │ \u001b[2mfloat32\u001b[0m[3,3,… │\n",
      "│              │             │                │                │               │\n",
      "│              │             │                │                │ \u001b[1m230 \u001b[0m\u001b[1;2m(920 B)\u001b[0m   │\n",
      "├──────────────┼─────────────┼────────────────┼────────────────┼───────────────┤\n",
      "│ norm2        │ GroupNorm   │ \u001b[2mfloat32\u001b[0m[1,64,… │ \u001b[2mfloat32\u001b[0m[1,64,… │ bias:         │\n",
      "│              │             │                │                │ \u001b[2mfloat32\u001b[0m[5]    │\n",
      "│              │             │                │                │ scale:        │\n",
      "│              │             │                │                │ \u001b[2mfloat32\u001b[0m[5]    │\n",
      "│              │             │                │                │               │\n",
      "│              │             │                │                │ \u001b[1m10 \u001b[0m\u001b[1;2m(40 B)\u001b[0m     │\n",
      "├──────────────┼─────────────┼────────────────┼────────────────┼───────────────┤\n",
      "│ conv2        │ Conv        │ \u001b[2mfloat32\u001b[0m[1,64,… │ \u001b[2mfloat32\u001b[0m[1,64,… │ bias:         │\n",
      "│              │             │                │                │ \u001b[2mfloat32\u001b[0m[5]    │\n",
      "│              │             │                │                │ kernel:       │\n",
      "│              │             │                │                │ \u001b[2mfloat32\u001b[0m[3,3,… │\n",
      "│              │             │                │                │               │\n",
      "│              │             │                │                │ \u001b[1m230 \u001b[0m\u001b[1;2m(920 B)\u001b[0m   │\n",
      "├──────────────┼─────────────┼────────────────┼────────────────┼───────────────┤\n",
      "│ nin_shortcut │ Conv        │ \u001b[2mfloat32\u001b[0m[1,64,… │ \u001b[2mfloat32\u001b[0m[1,64,… │ bias:         │\n",
      "│              │             │                │                │ \u001b[2mfloat32\u001b[0m[5]    │\n",
      "│              │             │                │                │ kernel:       │\n",
      "│              │             │                │                │ \u001b[2mfloat32\u001b[0m[1,1,… │\n",
      "│              │             │                │                │               │\n",
      "│              │             │                │                │ \u001b[1m30 \u001b[0m\u001b[1;2m(120 B)\u001b[0m    │\n",
      "├──────────────┼─────────────┼────────────────┼────────────────┼───────────────┤\n",
      "│\u001b[1m \u001b[0m\u001b[1m            \u001b[0m\u001b[1m \u001b[0m│\u001b[1m \u001b[0m\u001b[1m           \u001b[0m\u001b[1m \u001b[0m│\u001b[1m \u001b[0m\u001b[1m              \u001b[0m\u001b[1m \u001b[0m│\u001b[1m \u001b[0m\u001b[1m         Total\u001b[0m\u001b[1m \u001b[0m│\u001b[1m \u001b[0m\u001b[1m510 \u001b[0m\u001b[1;2m(2.0 KB)\u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m│\n",
      "└──────────────┴─────────────┴────────────────┴────────────────┴───────────────┘\n",
      "\u001b[1m                                                                                \u001b[0m\n",
      "\u001b[1m                         Total Parameters: 510 \u001b[0m\u001b[1;2m(2.0 KB)\u001b[0m\u001b[1m                         \u001b[0m\n",
      "\n",
      "\n",
      "+----------------------------+--------------+------+----------+-------+\n",
      "| Name                       | Shape        | Size | Mean     | Std   |\n",
      "+----------------------------+--------------+------+----------+-------+\n",
      "| params/conv1/bias          | (5,)         | 5    | 0.0      | 0.0   |\n",
      "| params/conv1/kernel        | (3, 3, 5, 5) | 225  | -0.0101  | 0.15  |\n",
      "| params/conv2/bias          | (5,)         | 5    | 0.0      | 0.0   |\n",
      "| params/conv2/kernel        | (3, 3, 5, 5) | 225  | -0.00635 | 0.149 |\n",
      "| params/nin_shortcut/bias   | (5,)         | 5    | 0.0      | 0.0   |\n",
      "| params/nin_shortcut/kernel | (1, 1, 5, 5) | 25   | 0.108    | 0.466 |\n",
      "| params/norm1/bias          | (5,)         | 5    | 0.0      | 0.0   |\n",
      "| params/norm1/scale         | (5,)         | 5    | 1.0      | 0.0   |\n",
      "| params/norm2/bias          | (5,)         | 5    | 0.0      | 0.0   |\n",
      "| params/norm2/scale         | (5,)         | 5    | 1.0      | 0.0   |\n",
      "+----------------------------+--------------+------+----------+-------+\n",
      "Total: 510\n"
     ]
    }
   ],
   "source": [
    "# Generate random input tensors\n",
    "x = jnp.zeros((1, 64, 64, 5))\n",
    "rng = jax.random.PRNGKey(0)\n",
    "\n",
    "# Initialize ResnetBlock\n",
    "resnet_block = ResnetBlock(\n",
    "    in_channels=5,\n",
    "    out_channels=5,\n",
    ")\n",
    "\n",
    "params = resnet_block.init(rng, x)\n",
    "# Apply ResnetBlock using the apply method\n",
    "output = resnet_block.apply({'params': params['params']}, x)\n",
    "print(output.shape)\n",
    "\n",
    "print(resnet_block.tabulate(rng, x))\n",
    "\n",
    "print(parameter_overview.get_parameter_overview(params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x : (1, 64, 64, 5)\n",
      "Conv_in : (1, 64, 64, 5)\n",
      "Down : (1, 16, 16, 20)\n",
      "Mid : (1, 16, 16, 20)\n",
      "Conv_out : (1, 16, 16, 5)\n",
      "x : (1, 64, 64, 5)\n",
      "Conv_in : (1, 64, 64, 5)\n",
      "Down : (1, 16, 16, 20)\n",
      "Mid : (1, 16, 16, 20)\n",
      "Conv_out : (1, 16, 16, 5)\n",
      "Encoder output : (1, 16, 16, 5)\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "rng = jax.random.PRNGKey(0)\n",
    "input_shape = (1, 64, 64, 5) \n",
    "\n",
    "# Initialize Encoder\n",
    "encoder = Encoder(ch_mult=(1,2,4),\n",
    "                  num_res_blocks=2,\n",
    "                  double_z=False,\n",
    "                  z_channels=5,\n",
    "                  resolution=64,\n",
    "                  in_channels=5,\n",
    "                  out_ch=5,\n",
    "                  ch=5,                  \n",
    "                 )\n",
    "\n",
    "# Apply Encoder\n",
    "params = encoder.init(rng, x=jnp.ones(input_shape))\n",
    "output = encoder.apply(params, x=jnp.ones(input_shape))\n",
    "\n",
    "# Print the output shape\n",
    "print(\"Encoder output :\", output.shape)  # Shape: (1, 16, 16, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Upsample(nn.Module):\n",
    "    in_channels: int\n",
    "    \n",
    "    def setup(self):\n",
    "        self.conv = nn.Conv(\n",
    "            self.in_channels,\n",
    "            kernel_size=(3, 3),\n",
    "            strides=(1, 1),\n",
    "            padding=((1, 1), (1, 1)),\n",
    "            )\n",
    "\n",
    "    def __call__(self, hs):\n",
    "        batch, height, width, channels = hs.shape\n",
    "        hs = jax.image.resize(\n",
    "            hs,\n",
    "            shape=(batch, height * 2, width * 2, channels),\n",
    "            method=\"nearest\",\n",
    "        )\n",
    "        hs = self.conv(hs)\n",
    "        return hs\n",
    "    \n",
    "    \n",
    "class UpsamplingBlock(nn.Module):\n",
    "    ch: int\n",
    "    ch_mult: tuple\n",
    "    num_res_blocks: int\n",
    "    resolution: int\n",
    "    block_idx: int\n",
    "    \n",
    "    def setup(self):\n",
    "        \n",
    "        self.ch_mult_ = self.ch_mult \n",
    "        self.num_resolutions = len(self.ch_mult_)\n",
    "        \n",
    "        if self.block_idx == self.num_resolutions - 1:\n",
    "            block_in = self.ch * self.ch_mult_[-1]\n",
    "        else:\n",
    "            block_in = self.ch * self.ch_mult_[self.block_idx + 1]\n",
    "\n",
    "        block_out = self.ch * self.ch_mult_[self.block_idx]\n",
    "        \n",
    "        res_blocks = []\n",
    "        for _ in range(self.num_res_blocks + 1):\n",
    "            res_blocks.append(\n",
    "                ResnetBlock(block_in,\n",
    "                            block_out))\n",
    "                            \n",
    "        block_in = block_out\n",
    "        \n",
    "        self.block = res_blocks\n",
    "\n",
    "        self.upsample = None\n",
    "        if self.block_idx != 0:\n",
    "            self.upsample = Upsample(block_in)\n",
    "\n",
    "    def __call__(self, h):\n",
    "        for i, res_block in enumerate(self.block):\n",
    "            h = res_block(h)\n",
    "\n",
    "        if self.upsample is not None:\n",
    "            h = self.upsample(h)\n",
    "\n",
    "        return h    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 32, 32, 5)\n",
      "\n",
      "\u001b[3m                            UpsamplingBlock Summary                             \u001b[0m\n",
      "┏━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━┓\n",
      "┃\u001b[1m \u001b[0m\u001b[1mpath         \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mmodule       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1minputs       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1moutputs      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mparams      \u001b[0m\u001b[1m \u001b[0m┃\n",
      "┡━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━┩\n",
      "│               │ UpsamplingBl… │ \u001b[2mfloat32\u001b[0m[1,16… │ \u001b[2mfloat32\u001b[0m[1,32… │              │\n",
      "├───────────────┼───────────────┼───────────────┼───────────────┼──────────────┤\n",
      "│ block_0       │ ResnetBlock   │ \u001b[2mfloat32\u001b[0m[1,16… │ \u001b[2mfloat32\u001b[0m[1,16… │              │\n",
      "├───────────────┼───────────────┼───────────────┼───────────────┼──────────────┤\n",
      "│ block_0/norm1 │ GroupNorm     │ \u001b[2mfloat32\u001b[0m[1,16… │ \u001b[2mfloat32\u001b[0m[1,16… │ bias:        │\n",
      "│               │               │               │               │ \u001b[2mfloat32\u001b[0m[5]   │\n",
      "│               │               │               │               │ scale:       │\n",
      "│               │               │               │               │ \u001b[2mfloat32\u001b[0m[5]   │\n",
      "│               │               │               │               │              │\n",
      "│               │               │               │               │ \u001b[1m10 \u001b[0m\u001b[1;2m(40 B)\u001b[0m    │\n",
      "├───────────────┼───────────────┼───────────────┼───────────────┼──────────────┤\n",
      "│ block_0/conv1 │ Conv          │ \u001b[2mfloat32\u001b[0m[1,16… │ \u001b[2mfloat32\u001b[0m[1,16… │ bias:        │\n",
      "│               │               │               │               │ \u001b[2mfloat32\u001b[0m[5]   │\n",
      "│               │               │               │               │ kernel:      │\n",
      "│               │               │               │               │ \u001b[2mfloat32\u001b[0m[3,3… │\n",
      "│               │               │               │               │              │\n",
      "│               │               │               │               │ \u001b[1m230 \u001b[0m\u001b[1;2m(920 B)\u001b[0m  │\n",
      "├───────────────┼───────────────┼───────────────┼───────────────┼──────────────┤\n",
      "│ block_0/norm2 │ GroupNorm     │ \u001b[2mfloat32\u001b[0m[1,16… │ \u001b[2mfloat32\u001b[0m[1,16… │ bias:        │\n",
      "│               │               │               │               │ \u001b[2mfloat32\u001b[0m[5]   │\n",
      "│               │               │               │               │ scale:       │\n",
      "│               │               │               │               │ \u001b[2mfloat32\u001b[0m[5]   │\n",
      "│               │               │               │               │              │\n",
      "│               │               │               │               │ \u001b[1m10 \u001b[0m\u001b[1;2m(40 B)\u001b[0m    │\n",
      "├───────────────┼───────────────┼───────────────┼───────────────┼──────────────┤\n",
      "│ block_0/conv2 │ Conv          │ \u001b[2mfloat32\u001b[0m[1,16… │ \u001b[2mfloat32\u001b[0m[1,16… │ bias:        │\n",
      "│               │               │               │               │ \u001b[2mfloat32\u001b[0m[5]   │\n",
      "│               │               │               │               │ kernel:      │\n",
      "│               │               │               │               │ \u001b[2mfloat32\u001b[0m[3,3… │\n",
      "│               │               │               │               │              │\n",
      "│               │               │               │               │ \u001b[1m230 \u001b[0m\u001b[1;2m(920 B)\u001b[0m  │\n",
      "├───────────────┼───────────────┼───────────────┼───────────────┼──────────────┤\n",
      "│ block_0/nin_… │ Conv          │ \u001b[2mfloat32\u001b[0m[1,16… │ \u001b[2mfloat32\u001b[0m[1,16… │ bias:        │\n",
      "│               │               │               │               │ \u001b[2mfloat32\u001b[0m[5]   │\n",
      "│               │               │               │               │ kernel:      │\n",
      "│               │               │               │               │ \u001b[2mfloat32\u001b[0m[1,1… │\n",
      "│               │               │               │               │              │\n",
      "│               │               │               │               │ \u001b[1m30 \u001b[0m\u001b[1;2m(120 B)\u001b[0m   │\n",
      "├───────────────┼───────────────┼───────────────┼───────────────┼──────────────┤\n",
      "│ block_1       │ ResnetBlock   │ \u001b[2mfloat32\u001b[0m[1,16… │ \u001b[2mfloat32\u001b[0m[1,16… │              │\n",
      "├───────────────┼───────────────┼───────────────┼───────────────┼──────────────┤\n",
      "│ block_1/norm1 │ GroupNorm     │ \u001b[2mfloat32\u001b[0m[1,16… │ \u001b[2mfloat32\u001b[0m[1,16… │ bias:        │\n",
      "│               │               │               │               │ \u001b[2mfloat32\u001b[0m[5]   │\n",
      "│               │               │               │               │ scale:       │\n",
      "│               │               │               │               │ \u001b[2mfloat32\u001b[0m[5]   │\n",
      "│               │               │               │               │              │\n",
      "│               │               │               │               │ \u001b[1m10 \u001b[0m\u001b[1;2m(40 B)\u001b[0m    │\n",
      "├───────────────┼───────────────┼───────────────┼───────────────┼──────────────┤\n",
      "│ block_1/conv1 │ Conv          │ \u001b[2mfloat32\u001b[0m[1,16… │ \u001b[2mfloat32\u001b[0m[1,16… │ bias:        │\n",
      "│               │               │               │               │ \u001b[2mfloat32\u001b[0m[5]   │\n",
      "│               │               │               │               │ kernel:      │\n",
      "│               │               │               │               │ \u001b[2mfloat32\u001b[0m[3,3… │\n",
      "│               │               │               │               │              │\n",
      "│               │               │               │               │ \u001b[1m230 \u001b[0m\u001b[1;2m(920 B)\u001b[0m  │\n",
      "├───────────────┼───────────────┼───────────────┼───────────────┼──────────────┤\n",
      "│ block_1/norm2 │ GroupNorm     │ \u001b[2mfloat32\u001b[0m[1,16… │ \u001b[2mfloat32\u001b[0m[1,16… │ bias:        │\n",
      "│               │               │               │               │ \u001b[2mfloat32\u001b[0m[5]   │\n",
      "│               │               │               │               │ scale:       │\n",
      "│               │               │               │               │ \u001b[2mfloat32\u001b[0m[5]   │\n",
      "│               │               │               │               │              │\n",
      "│               │               │               │               │ \u001b[1m10 \u001b[0m\u001b[1;2m(40 B)\u001b[0m    │\n",
      "├───────────────┼───────────────┼───────────────┼───────────────┼──────────────┤\n",
      "│ block_1/conv2 │ Conv          │ \u001b[2mfloat32\u001b[0m[1,16… │ \u001b[2mfloat32\u001b[0m[1,16… │ bias:        │\n",
      "│               │               │               │               │ \u001b[2mfloat32\u001b[0m[5]   │\n",
      "│               │               │               │               │ kernel:      │\n",
      "│               │               │               │               │ \u001b[2mfloat32\u001b[0m[3,3… │\n",
      "│               │               │               │               │              │\n",
      "│               │               │               │               │ \u001b[1m230 \u001b[0m\u001b[1;2m(920 B)\u001b[0m  │\n",
      "├───────────────┼───────────────┼───────────────┼───────────────┼──────────────┤\n",
      "│ block_1/nin_… │ Conv          │ \u001b[2mfloat32\u001b[0m[1,16… │ \u001b[2mfloat32\u001b[0m[1,16… │ bias:        │\n",
      "│               │               │               │               │ \u001b[2mfloat32\u001b[0m[5]   │\n",
      "│               │               │               │               │ kernel:      │\n",
      "│               │               │               │               │ \u001b[2mfloat32\u001b[0m[1,1… │\n",
      "│               │               │               │               │              │\n",
      "│               │               │               │               │ \u001b[1m30 \u001b[0m\u001b[1;2m(120 B)\u001b[0m   │\n",
      "├───────────────┼───────────────┼───────────────┼───────────────┼──────────────┤\n",
      "│ block_2       │ ResnetBlock   │ \u001b[2mfloat32\u001b[0m[1,16… │ \u001b[2mfloat32\u001b[0m[1,16… │              │\n",
      "├───────────────┼───────────────┼───────────────┼───────────────┼──────────────┤\n",
      "│ block_2/norm1 │ GroupNorm     │ \u001b[2mfloat32\u001b[0m[1,16… │ \u001b[2mfloat32\u001b[0m[1,16… │ bias:        │\n",
      "│               │               │               │               │ \u001b[2mfloat32\u001b[0m[5]   │\n",
      "│               │               │               │               │ scale:       │\n",
      "│               │               │               │               │ \u001b[2mfloat32\u001b[0m[5]   │\n",
      "│               │               │               │               │              │\n",
      "│               │               │               │               │ \u001b[1m10 \u001b[0m\u001b[1;2m(40 B)\u001b[0m    │\n",
      "├───────────────┼───────────────┼───────────────┼───────────────┼──────────────┤\n",
      "│ block_2/conv1 │ Conv          │ \u001b[2mfloat32\u001b[0m[1,16… │ \u001b[2mfloat32\u001b[0m[1,16… │ bias:        │\n",
      "│               │               │               │               │ \u001b[2mfloat32\u001b[0m[5]   │\n",
      "│               │               │               │               │ kernel:      │\n",
      "│               │               │               │               │ \u001b[2mfloat32\u001b[0m[3,3… │\n",
      "│               │               │               │               │              │\n",
      "│               │               │               │               │ \u001b[1m230 \u001b[0m\u001b[1;2m(920 B)\u001b[0m  │\n",
      "├───────────────┼───────────────┼───────────────┼───────────────┼──────────────┤\n",
      "│ block_2/norm2 │ GroupNorm     │ \u001b[2mfloat32\u001b[0m[1,16… │ \u001b[2mfloat32\u001b[0m[1,16… │ bias:        │\n",
      "│               │               │               │               │ \u001b[2mfloat32\u001b[0m[5]   │\n",
      "│               │               │               │               │ scale:       │\n",
      "│               │               │               │               │ \u001b[2mfloat32\u001b[0m[5]   │\n",
      "│               │               │               │               │              │\n",
      "│               │               │               │               │ \u001b[1m10 \u001b[0m\u001b[1;2m(40 B)\u001b[0m    │\n",
      "├───────────────┼───────────────┼───────────────┼───────────────┼──────────────┤\n",
      "│ block_2/conv2 │ Conv          │ \u001b[2mfloat32\u001b[0m[1,16… │ \u001b[2mfloat32\u001b[0m[1,16… │ bias:        │\n",
      "│               │               │               │               │ \u001b[2mfloat32\u001b[0m[5]   │\n",
      "│               │               │               │               │ kernel:      │\n",
      "│               │               │               │               │ \u001b[2mfloat32\u001b[0m[3,3… │\n",
      "│               │               │               │               │              │\n",
      "│               │               │               │               │ \u001b[1m230 \u001b[0m\u001b[1;2m(920 B)\u001b[0m  │\n",
      "├───────────────┼───────────────┼───────────────┼───────────────┼──────────────┤\n",
      "│ block_2/nin_… │ Conv          │ \u001b[2mfloat32\u001b[0m[1,16… │ \u001b[2mfloat32\u001b[0m[1,16… │ bias:        │\n",
      "│               │               │               │               │ \u001b[2mfloat32\u001b[0m[5]   │\n",
      "│               │               │               │               │ kernel:      │\n",
      "│               │               │               │               │ \u001b[2mfloat32\u001b[0m[1,1… │\n",
      "│               │               │               │               │              │\n",
      "│               │               │               │               │ \u001b[1m30 \u001b[0m\u001b[1;2m(120 B)\u001b[0m   │\n",
      "├───────────────┼───────────────┼───────────────┼───────────────┼──────────────┤\n",
      "│ upsample      │ Upsample      │ \u001b[2mfloat32\u001b[0m[1,16… │ \u001b[2mfloat32\u001b[0m[1,32… │              │\n",
      "├───────────────┼───────────────┼───────────────┼───────────────┼──────────────┤\n",
      "│ upsample/conv │ Conv          │ \u001b[2mfloat32\u001b[0m[1,32… │ \u001b[2mfloat32\u001b[0m[1,32… │ bias:        │\n",
      "│               │               │               │               │ \u001b[2mfloat32\u001b[0m[5]   │\n",
      "│               │               │               │               │ kernel:      │\n",
      "│               │               │               │               │ \u001b[2mfloat32\u001b[0m[3,3… │\n",
      "│               │               │               │               │              │\n",
      "│               │               │               │               │ \u001b[1m230 \u001b[0m\u001b[1;2m(920 B)\u001b[0m  │\n",
      "├───────────────┼───────────────┼───────────────┼───────────────┼──────────────┤\n",
      "│\u001b[1m \u001b[0m\u001b[1m             \u001b[0m\u001b[1m \u001b[0m│\u001b[1m \u001b[0m\u001b[1m             \u001b[0m\u001b[1m \u001b[0m│\u001b[1m \u001b[0m\u001b[1m             \u001b[0m\u001b[1m \u001b[0m│\u001b[1m \u001b[0m\u001b[1m        Total\u001b[0m\u001b[1m \u001b[0m│\u001b[1m \u001b[0m\u001b[1m1,760 \u001b[0m\u001b[1;2m(7.0 \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m│\n",
      "│\u001b[1m               \u001b[0m│\u001b[1m               \u001b[0m│\u001b[1m               \u001b[0m│\u001b[1m               \u001b[0m│\u001b[1m \u001b[0m\u001b[1;2mKB)\u001b[0m\u001b[1m         \u001b[0m\u001b[1m \u001b[0m│\n",
      "└───────────────┴───────────────┴───────────────┴───────────────┴──────────────┘\n",
      "\u001b[1m                                                                                \u001b[0m\n",
      "\u001b[1m                        Total Parameters: 1,760 \u001b[0m\u001b[1;2m(7.0 KB)\u001b[0m\u001b[1m                        \u001b[0m\n",
      "\n",
      "\n",
      "+------------------------------------+--------------+------+-----------+-------+\n",
      "| Name                               | Shape        | Size | Mean      | Std   |\n",
      "+------------------------------------+--------------+------+-----------+-------+\n",
      "| params/block_0/conv1/bias          | (5,)         | 5    | 0.0       | 0.0   |\n",
      "| params/block_0/conv1/kernel        | (3, 3, 5, 5) | 225  | 0.00227   | 0.136 |\n",
      "| params/block_0/conv2/bias          | (5,)         | 5    | 0.0       | 0.0   |\n",
      "| params/block_0/conv2/kernel        | (3, 3, 5, 5) | 225  | 0.016     | 0.16  |\n",
      "| params/block_0/nin_shortcut/bias   | (5,)         | 5    | 0.0       | 0.0   |\n",
      "| params/block_0/nin_shortcut/kernel | (1, 1, 5, 5) | 25   | 0.16      | 0.447 |\n",
      "| params/block_0/norm1/bias          | (5,)         | 5    | 0.0       | 0.0   |\n",
      "| params/block_0/norm1/scale         | (5,)         | 5    | 1.0       | 0.0   |\n",
      "| params/block_0/norm2/bias          | (5,)         | 5    | 0.0       | 0.0   |\n",
      "| params/block_0/norm2/scale         | (5,)         | 5    | 1.0       | 0.0   |\n",
      "| params/block_1/conv1/bias          | (5,)         | 5    | 0.0       | 0.0   |\n",
      "| params/block_1/conv1/kernel        | (3, 3, 5, 5) | 225  | -0.0155   | 0.145 |\n",
      "| params/block_1/conv2/bias          | (5,)         | 5    | 0.0       | 0.0   |\n",
      "| params/block_1/conv2/kernel        | (3, 3, 5, 5) | 225  | -0.0184   | 0.154 |\n",
      "| params/block_1/nin_shortcut/bias   | (5,)         | 5    | 0.0       | 0.0   |\n",
      "| params/block_1/nin_shortcut/kernel | (1, 1, 5, 5) | 25   | 0.00102   | 0.534 |\n",
      "| params/block_1/norm1/bias          | (5,)         | 5    | 0.0       | 0.0   |\n",
      "| params/block_1/norm1/scale         | (5,)         | 5    | 1.0       | 0.0   |\n",
      "| params/block_1/norm2/bias          | (5,)         | 5    | 0.0       | 0.0   |\n",
      "| params/block_1/norm2/scale         | (5,)         | 5    | 1.0       | 0.0   |\n",
      "| params/block_2/conv1/bias          | (5,)         | 5    | 0.0       | 0.0   |\n",
      "| params/block_2/conv1/kernel        | (3, 3, 5, 5) | 225  | 0.00154   | 0.145 |\n",
      "| params/block_2/conv2/bias          | (5,)         | 5    | 0.0       | 0.0   |\n",
      "| params/block_2/conv2/kernel        | (3, 3, 5, 5) | 225  | -0.000852 | 0.147 |\n",
      "| params/block_2/nin_shortcut/bias   | (5,)         | 5    | 0.0       | 0.0   |\n",
      "| params/block_2/nin_shortcut/kernel | (1, 1, 5, 5) | 25   | -0.00632  | 0.501 |\n",
      "| params/block_2/norm1/bias          | (5,)         | 5    | 0.0       | 0.0   |\n",
      "| params/block_2/norm1/scale         | (5,)         | 5    | 1.0       | 0.0   |\n",
      "| params/block_2/norm2/bias          | (5,)         | 5    | 0.0       | 0.0   |\n",
      "| params/block_2/norm2/scale         | (5,)         | 5    | 1.0       | 0.0   |\n",
      "| params/upsample/conv/bias          | (5,)         | 5    | 0.0       | 0.0   |\n",
      "| params/upsample/conv/kernel        | (3, 3, 5, 5) | 225  | 0.000205  | 0.146 |\n",
      "+------------------------------------+--------------+------+-----------+-------+\n",
      "Total: 1,760\n"
     ]
    }
   ],
   "source": [
    "from clu import parameter_overview\n",
    "\n",
    "# Generate random input tensors\n",
    "x = jnp.zeros((1, 16, 16, 5))\n",
    "rng = jax.random.PRNGKey(0)\n",
    "\n",
    "# Initialize UpsamplingBlock\n",
    "up_block = UpsamplingBlock(\n",
    "    ch=5,\n",
    "    ch_mult=(4,2,1),\n",
    "    num_res_blocks=2,\n",
    "    resolution=64,\n",
    "    block_idx=2,\n",
    ")\n",
    "\n",
    "params = up_block.init(rng, x)\n",
    "# Apply UpsamplingBlock using the apply method\n",
    "output = up_block.apply({'params': params['params']}, x)\n",
    "print(output.shape)\n",
    "\n",
    "print(up_block.tabulate(rng, x))\n",
    "\n",
    "print(parameter_overview.get_parameter_overview(params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    ch: int\n",
    "    out_ch: int\n",
    "    ch_mult: tuple\n",
    "    num_res_blocks: int\n",
    "    in_channels: int\n",
    "    resolution: int\n",
    "    z_channels: int\n",
    "    double_z: bool\n",
    "    \n",
    "    def setup(self):\n",
    "        \n",
    "        self.num_resolutions = len(self.ch_mult)\n",
    "        \n",
    "        block_in = self.ch*self.ch_mult[self.num_resolutions-1]\n",
    "        curr_res = self.resolution // 2**(self.num_resolutions-1)\n",
    "        self.z_shape = (1,self.z_channels,curr_res,curr_res)\n",
    "        \n",
    "        # z to block_in\n",
    "        self.conv_in = nn.Conv(\n",
    "            self.ch,\n",
    "            kernel_size=(3, 3),\n",
    "            strides=(1, 1),\n",
    "            padding=((1, 1), (1, 1)),\n",
    "        )\n",
    "               \n",
    "        print(\"Working with z of shape {} = {} dimensions.\".format(\n",
    "        self.z_shape, np.prod(self.z_shape)))\n",
    "        \n",
    "        # middle\n",
    "        self.mid = MidBlock(block_in)\n",
    "        \n",
    "        # upsampling\n",
    "        upsample_blocks = []\n",
    "        \n",
    "        for i_level in reversed(range(self.num_resolutions)):\n",
    "            upsample_blocks.append(\n",
    "                UpsamplingBlock(ch=self.ch,\n",
    "                                ch_mult=self.ch_mult,\n",
    "                                num_res_blocks=self.num_res_blocks,\n",
    "                                resolution=self.resolution,\n",
    "                                block_idx=i_level,\n",
    "                               ))\n",
    "            if i_level != 0:\n",
    "                curr_res = curr_res * 2\n",
    "        self.up = list(\n",
    "            reversed(upsample_blocks))  # reverse to get consistent order\n",
    "        \n",
    "        # end\n",
    "        self.norm_out = Normalize(num_groups=5)\n",
    "        self.conv_out = nn.Conv(\n",
    "            self.out_ch,\n",
    "            kernel_size=(3, 3),\n",
    "            strides=(1, 1),\n",
    "            padding=((1, 1), (1, 1)),\n",
    "        )\n",
    "        \n",
    "    def __call__(self, z):\n",
    "        # z to block_in\n",
    "        hs = self.conv_in(z)\n",
    "        \n",
    "        # middle\n",
    "        hs = self.mid(hs)\n",
    "        \n",
    "        # upsampling\n",
    "        for block in reversed(self.up):\n",
    "            hs = block(hs)\n",
    "            \n",
    "        # end\n",
    "        hs = self.norm_out(hs)\n",
    "        hs = nn.swish(hs)\n",
    "        hs = self.conv_out(hs)\n",
    "        \n",
    "        return hs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working with z of shape (1, 5, 16, 16) = 1280 dimensions.\n",
      "Working with z of shape (1, 5, 16, 16) = 1280 dimensions.\n",
      "Decoder output : (1, 64, 64, 5)\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "rng = jax.random.PRNGKey(0)\n",
    "input_shape = (1, 16, 16, 5) \n",
    "\n",
    "# Initialize ResnetBlock\n",
    "decoder = Decoder(ch_mult=(1,2,4),\n",
    "                  num_res_blocks=2,\n",
    "                  double_z=False,\n",
    "                  z_channels=5,\n",
    "                  resolution=64,\n",
    "                  in_channels=5,\n",
    "                  out_ch=5,\n",
    "                  ch=5,                  \n",
    "                 )\n",
    "\n",
    "# Apply Resnet\n",
    "params = decoder.init(rng, z=jnp.ones(input_shape))\n",
    "output = decoder.apply(params, z=jnp.ones(input_shape))\n",
    "\n",
    "# Print the output shape\n",
    "print(\"Decoder output :\", output.shape)  # Shape: (1, 64, 64, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
